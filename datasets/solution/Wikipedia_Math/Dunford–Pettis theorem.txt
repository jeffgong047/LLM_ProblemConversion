Mathematical concept
In mathematics, uniform integrability is an important concept in real analysis, functional analysis and measure theory, and plays a vital role in the theory of martingales.


Measure-theoretic definition[edit]
Uniform integrability is an extension to the notion of a family of functions being dominated in L1_1 which is central in dominated convergence.
Several textbooks on real analysis and measure theory use the following definition:[1][2]
Definition A:  Let (X,M,Î¼)(X,ğ”,Î¼) be a positive measure space. A set Î¦âŠ‚L1(Î¼)Î¦^1(Î¼) is called uniformly integrable if supfâˆˆÎ¦â€–fâ€–L1(Î¼)<âˆsup_fâˆˆÎ¦f_L_1(Î¼)<âˆ, and to each Îµ>0Îµ>0 there corresponds a Î´>0Î´>0 such that

âˆ«E|f|dÎ¼<Îµâˆ«_E|f| dÎ¼<Îµ
whenever fâˆˆÎ¦âˆˆÎ¦ and Î¼(E)<Î´.Î¼(E)<Î´.
Definition A is rather restrictive for infinite measure spaces. A more general definition[3] of uniform integrability that works well in general measures spaces was introduced by G. A. Hunt.
Definition H: Let (X,M,Î¼)(X,ğ”,Î¼) be a positive measure space. A set Î¦âŠ‚L1(Î¼)Î¦^1(Î¼) is  called uniformly integrable if and only if

infgâˆˆL+1(Î¼)supfâˆˆÎ¦âˆ«|f|>g|f|dÎ¼=0inf_g_+^1(Î¼)sup_fâˆˆÎ¦âˆ«_{|f|>g}|f| dÎ¼=0
where L+1(Î¼)=gâˆˆL1(Î¼):gâ‰¥0_+^1(Î¼)={g^1(Î¼):gâ‰¥0}.
For finite measure spaces the following result[4] follows from Definition H:
Theorem 1: If (X,M,Î¼)(X,ğ”,Î¼) is a (positive) finite  measure space, then  a set Î¦âŠ‚L1(Î¼)Î¦^1(Î¼) is uniformly integrable[clarification needed] if and only if

infaâ‰¥0supfâˆˆÎ¦âˆ«|f|>a|f|dÎ¼=0inf_aâ‰¥0sup_fâˆˆÎ¦âˆ«_{|f|>a}|f| dÎ¼=0
Many textbooks in probability present Theorem 1 as the definition of uniform integrability in Probability spaces. When the space (X,M,Î¼)(X,ğ”,Î¼) is ÏƒÏƒ-finite, Definition H yields the following equivalency:
Theorem 2: Let (X,M,Î¼)(X,ğ”,Î¼) be a ÏƒÏƒ-finite measure space, and hâˆˆL1(Î¼)^1(Î¼) be such that h>0>0 almost surely. A set Î¦âŠ‚L1(Î¼)Î¦^1(Î¼) is uniformly integrable[clarification needed] if and only if supfâˆˆÎ¦â€–fâ€–L1(Î¼)<âˆsup_fâˆˆÎ¦f_L_1(Î¼)<âˆ, and for any Îµ>0Îµ>0, there exits Î´>0Î´>0 such that

supfâˆˆÎ¦âˆ«A|f|dÎ¼<Îµsup_fâˆˆÎ¦âˆ«_A|f| dÎ¼<Îµ
whenever âˆ«AhdÎ¼<Î´âˆ«_Ah dÎ¼<Î´.
In particular,  the equivalence of Definitions A and H for finite measures follows immediately from Theorem 2; for this case, the statement in Definition A is obtained by taking hâ‰¡1â‰¡1 in Theorem 2.

Probability definition[edit]
In the theory of probability, Definition A or the statement of Theorem 1 are often presented  as definitions of uniform integrability using the notation expectation of random variables.,[5][6][7] that is,
1. A class Cğ’ of random variables is called uniformly integrable if:

There exists a finite M such that, for every X in Cğ’, Eâ¡(|X|)â‰¤ME(|X|) and
For every Îµ>0Îµ>0 there exists Î´>0Î´>0 such that, for every measurable A such that P(A)â‰¤Î´(A)â‰¤Î´ and every X in Cğ’,  Eâ¡(|X|IA)â‰¤ÎµE(|X|I_A)â‰¤Îµ.
or alternatively
2.  A class Cğ’ of random variables is called uniformly integrable (UI) if for every Îµ>0Îµ>0 there exists Kâˆˆ[0,âˆ)âˆˆ[0,âˆ) such that Eâ¡(|X|I|X|â‰¥K)â‰¤ÎµforallXâˆˆCE(|X|I_|X|)â‰¤Îµ{forallXâˆˆğ’, where I|X|â‰¥K_|X| is the indicator function I|X|â‰¥K=1if|X|â‰¥K,0if|X|<K._|X|=1   if|X|,
0   if|X|<K..

Tightness and uniform integrability[edit]
One consequence of uniformly integrability of a class Cğ’  of random variables is that family of  laws or distributions Pâˆ˜|X|âˆ’1(â‹…):XâˆˆC{Pâˆ˜|X|^-1(Â·):Xâˆˆğ’} is tight. That is, for each Î´>0Î´>0, there exists a>0>0 such that
P(|X|>a)â‰¤Î´(|X|>a)â‰¤Î´
for all XâˆˆCâˆˆğ’.[8]
This however, does not mean that the family of measures VC:=Î¼X:Aâ†¦âˆ«A|X|dP,XâˆˆCğ’±_ğ’:={Î¼_X:Aâ†¦âˆ«_A|X| dP, Xâˆˆğ’} is tight. (In any case, tightness would require a topology on Î©Î© in order to be defined.)

Uniform absolute continuity[edit]
There is another  notion of uniformity, slightly different than uniform integrability,  which also has many applications in probability and measure theory, and which does not require random variables to have a finite integral[9]
Definition: Suppose (Î©,F,P)(Î©,â„±,P) is a probability space. A classed Cğ’ of random variables is   uniformly absolutely continuous with respect to P if for any Îµ>0Îµ>0, there is Î´>0Î´>0 such that
E[|X|IA]<Îµ[|X|I_A]<Îµ
whenever P(A)<Î´(A)<Î´.
It is equivalent to uniform integrability if the measure is finite and has no atoms.
The term "uniform absolute continuity" is not standard,[citation needed] but is used by some authors.[10][11]

Related corollaries[edit]
The following results apply to the probabilistic definition.[12]

Definition 1 could be rewritten by taking the limits as limKâ†’âˆsupXâˆˆCEâ¡(|X|I|X|â‰¥K)=0.lim_Kâ†’âˆsup_Xâˆˆğ’E(|X| I_|X|)=0.
A non-UI sequence. Let Î©=[0,1]âŠ‚RÎ©=[0,1]âŠ‚â„, and define Xn(Ï‰)=n,Ï‰âˆˆ(0,1/n),0,otherwise._n(Ï‰)=n,   Ï‰âˆˆ(0,1/n),
0,   otherwise. Clearly XnâˆˆL1_n^1, and indeed Eâ¡(|Xn|)=1,E(|X_n|)=1  for all n. However, Eâ¡(|Xn|I|Xn|â‰¥K)=1forallnâ‰¥K,E(|X_n|I_{|X_n|})=1{foralln, and comparing with definition 1, it is seen that the sequence is not uniformly integrable.
Non-UI sequence of RVs. The area under the strip is always equal to 1, but Xnâ†’0_nâ†’0 pointwise.
By using Definition 2 in the above example, it can be seen that the first clause is satisfied as L1^1 norm of all Xn_ns are 1 i.e., bounded. But the second clause does not hold as given any Î´Î´ positive, there is an interval (0,1/n)(0,1/n) with measure less than Î´Î´ and E[|Xm|:(0,1/n)]=1[|X_m|:(0,1/n)]=1 for all mâ‰¥n.
If X is a UI random variable, by splitting Eâ¡(|X|)=Eâ¡(|X|I|X|â‰¥K)+Eâ¡(|X|I|X|<K)E(|X|)=E(|X|I_{|X|})+E(|X|I_{|X|<K}) and bounding each of the two, it can be seen that a uniformly integrable random variable is always bounded in L1^1.
If any sequence of random variables Xn_n is dominated by an integrable, non-negative Y: that is, for all Ï‰ and n, |Xn(Ï‰)|â‰¤Y(Ï‰),Y(Ï‰)â‰¥0,Eâ¡(Y)<âˆ,|X_n(Ï‰)|(Ï‰),(Ï‰)â‰¥0,
operatornameE(Y)<âˆ, then the class Cğ’ of random variables Xn{X_n} is uniformly integrable.
A class of random variables bounded in Lp^p (p>1>1) is uniformly integrable.
Relevant theorems[edit]
In the following we use the probabilistic framework, but regardless of the finiteness of the measure, by adding the boundedness condition on the chosen subset of L1(Î¼)^1(Î¼).

Dunfordâ€“Pettis theorem[13][14]A class[clarification needed] of random variables XnâŠ‚L1(Î¼)_n^1(Î¼) is uniformly integrable if and only if it is relatively compact for the weak topology Ïƒ(L1,Lâˆ)Ïƒ(L^1,L^âˆ).[clarification needed][citation needed]
de la VallÃ©e-Poussin theorem[15][16]The family XÎ±Î±âˆˆAâŠ‚L1(Î¼){X_Î±}_Î±âˆˆA^1(Î¼) is uniformly integrable if and only if there exists a non-negative increasing convex function G(t)(t) such that limtâ†’âˆG(t)t=âˆandsupÎ±Eâ¡(G(|XÎ±|))<âˆ.lim_tâ†’âˆG(t)/t=âˆandsup_Î±E(G(|X_Î±|))<âˆ.
Relation to convergence of random variables[edit]
Main article: Convergence of random variables
A sequence Xn{X_n} converges to X in the L1_1 norm if and only if it converges in measure to X and it is uniformly integrable. In probability terms, a sequence of random variables converging in probability also converge in the mean if and only if they are uniformly integrable.[17] This is a generalization of Lebesgue's dominated convergence theorem, see Vitali convergence theorem.

Citations[edit]


^ Rudin, Walter (1987). Real and Complex Analysis (3Â ed.). Singapore: McGrawâ€“Hill Book Co. p.Â 133. ISBNÂ 0-07-054234-1.

^ Royden, H.L. & Fitzpatrick, P.M. (2010). Real Analysis (4Â ed.). Boston: Prentice Hall. p.Â 93. ISBNÂ 978-0-13-143747-0.

^ Hunt, G. A. (1966). Martingales et Processus de Markov. Paris: Dunod. p.Â 254.

^ Klenke, A. (2008). Probability Theory: A Comprehensive Course. Berlin: Springer Verlag. pp.Â 134â€“137. ISBNÂ 978-1-84800-047-6.

^ Williams, David (1997). Probability with Martingales (Repr.Â ed.). Cambridge: Cambridge Univ. Press. pp.Â 126â€“132. ISBNÂ 978-0-521-40605-5.

^ Gut, Allan (2005). Probability: A Graduate Course. Springer. pp.Â 214â€“218. ISBNÂ 0-387-22833-0.

^ Bass, Richard F. (2011). Stochastic Processes. Cambridge: Cambridge University Press. pp.Â 356â€“357. ISBNÂ 978-1-107-00800-7.

^ Gut 2005, p.Â 236.

^ Bass 2011, p.Â 356. sfn error: no target: CITEREFBass2011 (help)

^ Benedetto, J. J. (1976). Real Variable and Integration. Stuttgart: B. G. Teubner. p.Â 89. ISBNÂ 3-519-02209-5.

^ Burrill, C. W. (1972). Measure, Integration, and Probability. McGraw-Hill. p.Â 180. ISBNÂ 0-07-009223-0.

^ Gut 2005, pp.Â 215â€“216.

^ Dunford, Nelson (1938). "Uniformity in linear spaces". Transactions of the American Mathematical Society. 44 (2): 305â€“356. doi:10.1090/S0002-9947-1938-1501971-X. ISSNÂ 0002-9947.

^ Dunford, Nelson (1939). "A mean ergodic theorem". Duke Mathematical Journal. 5 (3): 635â€“646. doi:10.1215/S0012-7094-39-00552-1. ISSNÂ 0012-7094.

^ Meyer, P.A. (1966). Probability and Potentials, Blaisdell Publishing Co, N. Y. (p.19, Theorem T22).

^ Poussin, C. De La Vallee (1915). "Sur L'Integrale de Lebesgue". Transactions of the American Mathematical Society. 16 (4): 435â€“501. doi:10.2307/1988879. hdl:10338.dmlcz/127627. JSTORÂ 1988879.

^ Bogachev, Vladimir I. (2007). Measure Theory Volume I. Berlin Heidelberg: Springer-Verlag. p.Â 268. doi:10.1007/978-3-540-34514-5_4. ISBNÂ 978-3-540-34513-8.


References[edit]
Shiryaev, A.N. (1995). Probability (2Â ed.). New York: Springer-Verlag. pp.Â 187â€“188. ISBNÂ 978-0-387-94549-1.
Diestel, J. and Uhl, J. (1977). Vector measures, Mathematical Surveys 15, American Mathematical Society, Providence, RI ISBNÂ 978-0-8218-1515-1



