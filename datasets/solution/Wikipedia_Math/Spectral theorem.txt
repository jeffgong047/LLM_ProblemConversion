Result about when a matrix can be diagonalized
In mathematics, particularly linear algebra and functional analysis, a spectral theorem is a result about when a linear operator or matrix can be diagonalized (that is, represented as a diagonal matrix in some basis). This is extremely useful because computations involving a diagonalizable matrix can often be reduced to much simpler computations involving the corresponding diagonal matrix. The concept of diagonalization is relatively straightforward for operators on finite-dimensional vector spaces but requires some modification for operators on infinite-dimensional spaces. In general, the spectral theorem identifies a class of linear operators that can be modeled by multiplication operators, which are as simple as one can hope to find. In more abstract language, the spectral theorem is a statement about commutative C*-algebras. See also spectral theory for a historical perspective.
Examples of operators to which the spectral theorem applies are self-adjoint operators or more generally normal operators on Hilbert spaces.
The spectral theorem also provides a canonical decomposition, called the spectral decomposition, of the underlying vector space on which the operator acts.
Augustin-Louis Cauchy proved the spectral theorem for symmetric matrices, i.e., that every real, symmetric matrix is diagonalizable. In addition, Cauchy was the first to be systematic about determinants.[1][2] The spectral theorem as generalized by John von Neumann is today perhaps the most important result of operator theory.
This article mainly focuses on the simplest kind of spectral theorem, that for a self-adjoint operator on a Hilbert space. However, as noted above, the spectral theorem also holds for normal operators on a Hilbert space.


Finite-dimensional case[edit]
Hermitian maps and Hermitian matrices[edit]
We begin by considering a Hermitian matrix on Cn‚ÑÇ^n (but the following discussion will be adaptable to the more restrictive case of symmetric matrices on Rn‚Ñù^n). We consider a Hermitian map A on a finite-dimensional complex inner product space V endowed with a positive definite sesquilinear inner product ‚ü®‚ãÖ,‚ãÖ‚ü©‚ü®¬∑,¬∑‚ü©. The Hermitian condition on A means that for all x, y ‚àà V,
‚ü®Ax,y‚ü©=‚ü®x,Ay‚ü©.,y‚ü©=,Ay‚ü©.
An equivalent condition is that A* = A, where A* is the Hermitian conjugate of A. In the case that A is identified with a Hermitian matrix, the matrix of A* is equal to its conjugate transpose. (If A is a real matrix, then this is equivalent to AT = A, that is, A is a symmetric matrix.)
This condition implies that all eigenvalues of a Hermitian map are real: To see this, it is enough to apply it to the case when x = y is an eigenvector. (Recall that an eigenvector of a linear map A is a non-zero vector x such that Ax = Œªx for some scalar Œª. The value Œª is the corresponding eigenvalue. Moreover, the eigenvalues are roots of the characteristic polynomial.)


Theorem¬†‚Äî¬†If A is Hermitian on V, then there exists an orthonormal basis of V consisting of eigenvectors of A. Each eigenvalue of A is real.


We provide a sketch of a proof for the case where the underlying field of scalars is the complex numbers.
By the fundamental theorem of algebra, applied to the characteristic polynomial of A, there is at least one eigenvalue Œª1 and eigenvector e1, which must by definition be non-zero. Then since 
Œª1‚ü®e1,e1‚ü©=‚ü®A(e1),e1‚ü©=‚ü®e1,A(e1)‚ü©=Œª¬Ø1‚ü®e1,e1‚ü©,Œª_1_1,e_1‚ü©=(e_1),e_1‚ü©=_1,A(e_1)‚ü©=ŒªÃÖ_1_1,e_1‚ü©, 
we find that Œª1 is real. Now consider the space K = span{e1}‚ä•, the orthogonal complement of e1. By Hermiticity, K is an invariant subspace of A. Applying the same argument to K shows that A has an eigenvector e2 ‚àà K. Finite induction then finishes the proof.
The spectral theorem holds also for symmetric maps on finite-dimensional real inner product spaces, but the existence of an eigenvector does not follow immediately from the  fundamental theorem of algebra. To prove this, consider A as a Hermitian matrix and use the fact that all eigenvalues of a Hermitian matrix are real.
The matrix representation of A in a basis of eigenvectors is diagonal, and by the construction the proof gives a basis of mutually orthogonal eigenvectors; by choosing them to be unit vectors one obtains  an orthonormal basis of eigenvectors. A can be written as a linear combination of pairwise orthogonal projections, called its spectral decomposition. Let
VŒª=v‚ààV:Av=Œªv_Œª={v:Av=}
be the eigenspace corresponding to an eigenvalue Œª. Note that the definition does not depend on any choice of specific eigenvectors. V is the orthogonal direct sum of the spaces VŒª where the index ranges over eigenvalues. 
In other words, if PŒª denotes the orthogonal projection onto VŒª, and Œª1, ..., Œªm are the eigenvalues of A, then the spectral decomposition may be written as
A=Œª1PŒª1+‚ãØ+ŒªmPŒªm.=Œª_1P_Œª_1+‚ãØ+Œª_mP_Œª_m.
If the spectral decomposition of A is A=Œª1P1+‚ãØ+ŒªmPm=Œª_1P_1+‚ãØ+Œª_mP_m, then A2=(Œª1)2P1+‚ãØ+(Œªm)2Pm^2=(Œª_1)^2P_1+‚ãØ+(Œª_m)^2P_m and ŒºA=ŒºŒª1P1+‚ãØ+ŒºŒªmPm=ŒºŒª_1P_1+‚ãØ+ŒºŒª_mP_m for any scalar Œº.Œº. It follows that for any polynomial f one has
f(A)=f(Œª1)P1+‚ãØ+f(Œªm)Pm.(A)=f(Œª_1)P_1+‚ãØ+f(Œª_m)P_m.
The spectral decomposition is a special case of both the Schur decomposition and the singular value decomposition.

Normal matrices[edit]
Main article: Normal matrix
The spectral theorem extends to a more general class of matrices. Let A be an operator on a finite-dimensional inner product space. A is said to be normal  if A*A = AA*. One can show that A is normal if and only if it is unitarily diagonalizable. Proof: By the Schur decomposition, we can write any matrix as A = UTU*, where U is unitary and T is upper-triangular.
If A is normal, then one sees that TT* = T*T. Therefore, T must be diagonal since a normal upper triangular matrix is diagonal (see normal matrix). The converse is obvious.
In other words, A is normal if and only if there exists a unitary matrix U such that
A=UDU‚àó,=UDU^*,
where D is a diagonal matrix. Then, the entries of the diagonal of D are the eigenvalues of A. The column vectors of U are the eigenvectors of A and they are orthonormal. Unlike the Hermitian case, the entries of D need not be real.

Compact self-adjoint operators[edit]
Main article: Compact operator on Hilbert space
In the more general setting of Hilbert spaces, which may have an infinite dimension, the statement of the spectral theorem for compact self-adjoint operators is virtually the same as in the finite-dimensional case.
Theorem. Suppose A is a compact self-adjoint operator on a (real or complex) Hilbert space V. Then there is an orthonormal basis of V consisting of eigenvectors of A. Each eigenvalue is real.
As for Hermitian matrices, the key point is to prove the existence of at least one nonzero eigenvector. One cannot rely on determinants to show existence of eigenvalues, but one can use a maximization argument analogous to the variational characterization of eigenvalues. 
If the compactness assumption is removed, then it is not true that every self-adjoint operator has eigenvectors.

Bounded self-adjoint operators[edit]
See also: Eigenfunction and Self-adjoint operator ¬ß¬†Spectral theorem
Possible absence of eigenvectors[edit]
The next generalization we consider is that of bounded self-adjoint operators on a Hilbert space. Such operators may have no eigenvalues: for instance let A be the operator of multiplication by t on L2([0,1])^2([0,1]), that is,[3]
[AœÜ](t)=tœÜ(t).[AœÜ](t)=tœÜ(t).
This operator does not have any eigenvectors in L2([0,1])^2([0,1]), though it does have eigenvectors in a larger space. Namely the distribution œÜ(t)=Œ¥(t‚àít0)œÜ(t)=Œ¥(t-t_0), where Œ¥Œ¥ is the Dirac delta function, is an eigenvector when construed in an appropriate sense. The Dirac delta function is however not a function in the classical sense and does not lie in the Hilbert space L2[0, 1] or any other Banach space. Thus, the delta-functions are "generalized eigenvectors" of A but not eigenvectors in the usual sense.

Spectral subspaces and projection-valued measures[edit]
In the absence of (true) eigenvectors, one can look for subspaces consisting of almost eigenvectors. In the above example, for example, where [AœÜ](t)=tœÜ(t),[AœÜ](t)=tœÜ(t),  we might consider the subspace of functions supported on a small interval [a,a+Œµ][a,a+Œµ] inside [0,1][0,1]. This space is invariant under A and for any œÜœÜ in this subspace, AœÜœÜ is very close to aœÜœÜ. In this approach to the spectral theorem, if A is a bounded self-adjoint operator, then one looks for large families of such "spectral subspaces".[4] Each subspace, in turn, is encoded by the associated projection operator, and the collection of all the subspaces is then represented by a projection-valued measure. 
One formulation of the spectral theorem expresses the operator A as an integral of the coordinate function over the operator's spectrum œÉ(A)œÉ(A) with respect to a projection-valued measure.[5]
A=‚à´œÉ(A)ŒªdEŒª.=‚à´_œÉ(A)Œª dE_Œª.
When the self-adjoint operator in question is compact, this version of the spectral theorem reduces to something similar to the finite-dimensional spectral theorem above, except that the operator is expressed as a finite or countably infinite linear combination of projections, that is, the measure consists only of atoms.

Multiplication operator version[edit]
An alternative formulation of the spectral theorem says that every bounded self-adjoint operator is unitarily equivalent to a multiplication operator. The significance of this result is that multiplication operators are in many ways easy to understand.


Theorem.[6]¬†‚Äî¬†Let A  be a bounded self-adjoint operator on a Hilbert space H.  Then there is a measure space (X, Œ£, Œº) and a real-valued essentially bounded measurable function f on X and a unitary operator U:H ‚Üí L2(X, Œº) such that
U‚àóTU=A,^*TU=A,
where T is the multiplication operator:
[TœÜ](x)=f(x)œÜ(x),[TœÜ](x)=f(x)œÜ(x),
and ‚ÄñT‚Äñ=‚Äñf‚Äñ‚àûT=f_‚àû.


The spectral theorem is the beginning of the vast research area of functional analysis called operator theory; see also the spectral measure.
There is also an analogous spectral theorem for bounded normal operators on Hilbert spaces.  The only difference in the conclusion is that now f may be complex-valued.

Direct integrals[edit]
There is also a formulation of the spectral theorem in terms of direct integrals. It is similar to the multiplication-operator formulation, but more canonical.
Let A be a bounded self-adjoint operator and let œÉ(A)œÉ(A) be the spectrum of A. The direct-integral formulation of the spectral theorem associates two quantities to A. First, a measure ŒºŒº on œÉ(A)œÉ(A), and second, a family of Hilbert spaces HŒª,Œª‚ààœÉ(A).{H_Œª},  Œª‚ààœÉ(A). We then form the direct integral Hilbert space
‚à´R‚äïHŒªdŒº(Œª).‚à´_ùêë^‚äïH_Œª dŒº(Œª).
The elements of this space are functions (or "sections") s(Œª),Œª‚ààœÉ(A),(Œª),  Œª‚ààœÉ(A), such that s(Œª)‚ààHŒª(Œª)_Œª for all ŒªŒª. 
The direct-integral version of the spectral theorem may be expressed as follows:[7]


Theorem¬†‚Äî¬†If A is a bounded self-adjoint operator, then A is unitarily equivalent to the "multiplication by ŒªŒª" operator on ‚à´R‚äïHŒªdŒº(Œª)‚à´_ùêë^‚äïH_Œª dŒº(Œª)
for some measure ŒºŒº and some family HŒª{H_Œª} of Hilbert spaces. The measure ŒºŒº is uniquely determined by A up to measure-theoretic equivalence; that is, any two measure associated to the same A have the same sets of measure zero. The dimensions of the Hilbert spaces HŒª_Œª are uniquely determined by A up to a set of ŒºŒº-measure zero.


The spaces HŒª_Œª can be thought of as something like "eigenspaces" for A. Note, however, that unless the one-element set ŒªŒª has positive measure, the space HŒª_Œª is not actually a subspace of the direct integral. Thus, the HŒª_Œª's should be thought of as "generalized eigenspace"‚Äîthat is, the elements of HŒª_Œª are "eigenvectors" that do not actually belong to the Hilbert space.
Although both the multiplication-operator and direct integral formulations of the spectral theorem express a self-adjoint operator as unitarily equivalent to a multiplication operator, the direct integral approach is more canonical. First, the set over which the direct integral takes place (the spectrum of the operator) is canonical. Second, the function we are multiplying by is canonical in the direct-integral approach: Simply the function Œª‚Ü¶ŒªŒª‚Ü¶Œª.

Cyclic vectors and simple spectrum[edit]
A vector œÜœÜ is called a cyclic vector for A if the vectors œÜ,AœÜ,A2œÜ,‚Ä¶œÜ,AœÜ,A^2œÜ,‚Ä¶ span a dense subspace of the Hilbert space. Suppose A is a bounded self-adjoint operator for which a cyclic vector exists. In that case, there is no distinction between the direct-integral and multiplication-operator formulations of the spectral theorem. Indeed, in that case, there is a measure ŒºŒº on the spectrum œÉ(A)œÉ(A) of A such that A is unitarily equivalent to the "multiplication by ŒªŒª" operator on L2(œÉ(A),Œº)^2(œÉ(A),Œº).[8] This result represents A simultaneously as a multiplication operator and as a direct integral, since L2(œÉ(A),Œº)^2(œÉ(A),Œº) is just a direct integral in which each Hilbert space HŒª_Œª is just C‚ÑÇ.
Not every bounded self-adjoint operator admits a cyclic vector; indeed, by the uniqueness in the direct integral decomposition, this can occur only when all the HŒª_Œª's have dimension one. When this happens, we say that A has "simple spectrum" in the sense of spectral multiplicity theory. That is, a bounded self-adjoint operator that admits a cyclic vector should be thought of as the infinite-dimensional generalization of a self-adjoint matrix with distinct eigenvalues (i.e., each eigenvalue has multiplicity one).
Although not every A admits a cyclic vector, it is easy to see that we can decompose the Hilbert space as a direct sum of invariant subspaces on which A has a cyclic vector. This observation is the key to the proofs of the multiplication-operator and direct-integral forms of the spectral theorem.

Functional calculus[edit]
One important application of the spectral theorem (in whatever form) is the idea of defining a functional calculus. That is, given a function f defined on the spectrum of A, we wish to define an operator f(A)(A). If f is simply a positive power, f(x)=xn(x)=x^n, then f(A)(A) is just the n-th power of A, An^n. The interesting cases are where f is a nonpolynomial function such as a square root or an exponential. Either of the versions of the spectral theorem provides such a functional calculus.[9] In the direct-integral version, for example, f(A)(A) acts as the "multiplication by f" operator in the direct integral:
[f(A)s](Œª)=f(Œª)s(Œª).[f(A)s](Œª)=f(Œª)s(Œª).
That is to say, each space HŒª_Œª in the direct integral is a (generalized) eigenspace for f(A)(A) with eigenvalue f(Œª)(Œª).

General self-adjoint operators[edit]
Many important linear operators which occur in analysis, such as differential operators, are unbounded. There is also a spectral theorem for self-adjoint operators that applies in these cases.  To give an example, every constant-coefficient differential operator is unitarily equivalent to a multiplication operator. Indeed, the unitary operator that implements this equivalence is the Fourier transform; the multiplication operator is a type of Fourier multiplier.
In general, spectral theorem for self-adjoint operators may take several equivalent forms.[10] Notably, all of the formulations given in the previous section for bounded self-adjoint operators‚Äîthe projection-valued measure version, the multiplication-operator version, and the direct-integral version‚Äîcontinue to hold for unbounded self-adjoint operators, with small technical modifications to deal with domain issues.

See also[edit]
Hahn-Hellinger theorem¬†‚Äì Linear operator equal to its own adjointPages displaying short descriptions of redirect targets
Spectral theory of compact operators
Spectral theory of normal C*-algebras
Borel functional calculus
Spectral theory
Matrix decomposition
Canonical form
Jordan decomposition, of which the spectral decomposition is a special case.
Singular value decomposition, a generalisation of spectral theorem to arbitrary matrices.
Eigendecomposition of a matrix
Wiener‚ÄìKhinchin theorem
Notes[edit]


^ Hawkins, Thomas (1975). "Cauchy and the spectral theory of matrices". Historia Mathematica. 2: 1‚Äì29. doi:10.1016/0315-0860(75)90032-4.

^ A Short History of Operator Theory by Evans M. Harrell II

^ Hall 2013 Section 6.1

^ Hall 2013 Theorem 7.2.1

^ Hall 2013 Theorem 7.12

^ Hall 2013 Theorem 7.20

^ Hall 2013 Theorem 7.19

^ Hall 2013 Lemma 8.11

^ E.g., Hall 2013 Definition 7.13

^ See Section 10.1 of Hall 2013


References[edit]


Sheldon Axler, Linear Algebra Done Right, Springer Verlag, 1997
Hall, B.C. (2013), Quantum Theory for Mathematicians, Graduate Texts in Mathematics, vol.¬†267, Springer, ISBN¬†978-1461471158
Paul Halmos, "What Does the Spectral Theorem Say?", American Mathematical Monthly, volume 70, number 3 (1963), pages 241‚Äì247 Other link
M. Reed and B. Simon, Methods of Mathematical Physics, vols I‚ÄìIV, Academic Press 1972.
G. Teschl, Mathematical Methods in Quantum Mechanics with Applications to Schr√∂dinger Operators, https://www.mat.univie.ac.at/~gerald/ftp/book-schroe/, American Mathematical Society, 2009.
Valter Moretti (2017). Spectral Theory and Quantum Mechanics; Mathematical Foundations of Quantum Theories, Symmetries and Introduction to the Algebraic Formulation 2nd Edition. Springer. ISBN¬†978-3-319-70705-1.
vteFunctional analysis¬†(topics ‚Äì glossary)Spaces
Banach
Besov
Fr√©chet
Hilbert
H√∂lder
Nuclear
Orlicz
Schwartz
Sobolev
Topological vector
Properties
Barrelled
Complete
Dual (Algebraic/Topological)
Locally convex
Reflexive
Separable
Theorems
Hahn‚ÄìBanach
Riesz representation
Closed graph
Uniform boundedness principle
Kakutani fixed-point
Krein‚ÄìMilman
Min‚Äìmax
Gelfand‚ÄìNaimark
Banach‚ÄìAlaoglu
Operators
Adjoint
Bounded
Compact
Hilbert‚ÄìSchmidt
Normal
Nuclear
Trace class
Transpose
Unbounded
Unitary
Algebras
Banach algebra
C*-algebra
Spectrum of a C*-algebra
Operator algebra
Group algebra of a locally compact group
Von Neumann algebra
Open problems
Invariant subspace problem
Mahler's conjecture
Applications
Hardy space
Spectral theory of ordinary differential equations
Heat kernel
Index theorem
Calculus of variations
Functional calculus
Integral operator
Jones polynomial
Topological quantum field theory
Noncommutative geometry
Riemann hypothesis
Distribution (or Generalized functions)
Advanced topics
Approximation property
Balanced set
Choquet theory
Weak topology
Banach‚ÄìMazur distance
Tomita‚ÄìTakesaki theory

¬†Mathematics portal
 Category
Commons

vteSpectral theory and *-algebrasBasic concepts
Involution/*-algebra
Banach algebra
B*-algebra
C*-algebra
Noncommutative topology
Projection-valued measure
Spectrum
Spectrum of a C*-algebra
Spectral radius
Operator space
Main results
Gelfand‚ÄìMazur theorem
Gelfand‚ÄìNaimark theorem
Gelfand representation
Polar decomposition
Singular value decomposition
Spectral theorem
Spectral theory of normal C*-algebras
Special Elements/Operators
Isospectral
Normal operator
Hermitian/Self-adjoint operator
Unitary operator
Unit
Spectrum
Krein‚ÄìRutman theorem
Normal eigenvalue
Spectrum of a C*-algebra
Spectral radius
Spectral asymmetry
Spectral gap
Decomposition
Decomposition of a spectrum
Continuous
Point
Residual
Approximate point
Compression
Direct integral
Discrete
Spectral abscissa
Spectral Theorem
Borel functional calculus
Min-max theorem
Positive operator-valued measure
Projection-valued measure
Riesz projector
Rigged Hilbert space
Spectral theorem
Spectral theory of compact operators
Spectral theory of normal C*-algebras
Special algebras
Amenable Banach algebra
With an Approximate identity
Banach function algebra
Disk algebra
Nuclear C*-algebra
Uniform algebra
Von Neumann algebra
Tomita‚ÄìTakesaki theory
Finite-Dimensional
Alon‚ÄìBoppana bound
Bauer‚ÄìFike theorem
Numerical range
Schur‚ÄìHorn theorem
Generalizations
Dirac spectrum
Essential spectrum
Pseudospectrum
Structure space (Shilov boundary)
Miscellaneous
Abstract index group
Banach algebra cohomology
Cohen‚ÄìHewitt factorization theorem
Extensions of symmetric operators
Fredholm theory
Limiting absorption principle
Schr√∂der‚ÄìBernstein theorems for operator algebras
Sherman‚ÄìTakeda theorem
Unbounded operator
Examples
Wiener algebra
Applications
Almost Mathieu operator
Corona theorem
Hearing the shape of a drum (Dirichlet eigenvalue)
Heat kernel
Kuznetsov trace formula
Lax pair
Proto-value function
Ramanujan graph
Rayleigh‚ÄìFaber‚ÄìKrahn inequality
Spectral geometry
Spectral method
Spectral theory of ordinary differential equations
Sturm‚ÄìLiouville theory
Superstrong approximation
Transfer operator
Transform theory
Weyl law
Wiener‚ÄìKhinchin theorem




