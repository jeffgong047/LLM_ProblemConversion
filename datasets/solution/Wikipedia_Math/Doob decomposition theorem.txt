Mathematical theorem in stochastic processes
In the theory of stochastic processes in discrete time, a part of the mathematical theory of probability, the Doob decomposition theorem gives a unique decomposition of every adapted and integrable stochastic process as the sum of a martingale and a predictable process (or "drift") starting at zero. The theorem was proved by and is named for Joseph L. Doob.[1]
The analogous theorem in the continuous-time case is the Doobâ€“Meyer decomposition theorem.


Statement[edit]
Let (Î©,F,P)(Î©,â„±,â„™) be a probability space, I = {0, 1, 2, ..., N} with NâˆˆNâˆˆâ„• or I=N0=â„•_0 a finite or an infinite index set, (Fn)nâˆˆI(â„±_n)_n a filtration ofÂ Fâ„±, and X = (Xn)nâˆˆI an adapted stochastic process with E[|Xn|] < âˆž for all n âˆˆ I. Then there exist a martingale M = (Mn)nâˆˆI and an integrable  predictable process A = (An)nâˆˆI starting with  A0 = 0 such that Xn = Mn + An for every n âˆˆ I.
Here predictable means that An is Fnâˆ’1â„±_n-1-measurable for every n âˆˆ I \ {0}.
This decomposition is almost surely unique.[2][3][4]

Remark[edit]
The theorem is valid word by word also for stochastic processes X taking values in the d-dimensional Euclidean space Rdâ„^d or the complex vector space Cdâ„‚^d. This follows from the one-dimensional version by considering the components individually.

Proof[edit]
Existence[edit]
Using conditional expectations, define the processes A and M, for every n âˆˆ I, explicitly by




An=âˆ‘k=1n(E[Xk|Fkâˆ’1]âˆ’Xkâˆ’1)_n=âˆ‘_k=1^n(ð”¼[X_k | â„±_k-1]-X_k-1)





Â 

Â 

Â 



Â 



(1)

and




Mn=X0+âˆ‘k=1n(Xkâˆ’E[Xk|Fkâˆ’1]),_n=X_0+âˆ‘_k=1^n(X_k-ð”¼[X_k | â„±_k-1]),





Â 

Â 

Â 



Â 



(2)

where the sums for n = 0 are empty and defined as zero. Here A adds up the expected increments of X, and M adds up the surprises, i.e., the part of every Xk that is not known one time step before.
Due to these definitions, An+1 (if n + 1 âˆˆ I) and Mn are Fn-measurable because the process X is adapted, E[|An|] < âˆž and E[|Mn|] < âˆž because the process X is integrable, and the decomposition Xn = Mn + An is valid for every n âˆˆ I. The martingale property

E[Mnâˆ’Mnâˆ’1|Fnâˆ’1]=0ð”¼[M_n-M_n-1 | â„±_n-1]=0Â Â Â Â a.s.
also follows from the above definition (2), for every n âˆˆ I \ {0}.

Uniqueness[edit]
To prove uniqueness, let X = M' + A' be an additional decomposition. Then the process YÂ :=  M âˆ’ M' = A' âˆ’ A is a martingale, implying that

E[Yn|Fnâˆ’1]=Ynâˆ’1ð”¼[Y_n | â„±_n-1]=Y_n-1Â Â Â Â a.s.,
and also predictable, implying that

E[Yn|Fnâˆ’1]=Ynð”¼[Y_n | â„±_n-1]=Y_nÂ Â Â Â a.s.
for any n âˆˆ I \ {0}. Since Y0 = A'0 âˆ’ A0 = 0 by the convention about the starting point of the predictable processes, this implies iteratively that Yn = 0 almost surely for all n âˆˆ I, hence the decomposition is almost surely unique.

Corollary[edit]
A real-valued stochastic process X is a submartingale if and only if it has a Doob decomposition into a martingale M and an integrable predictable process A that is almost surely increasing.[5] It is a supermartingale, if and only if A is almost surely decreasing.

Proof[edit]
If X is a submartingale, then

E[Xk|Fkâˆ’1]â‰¥Xkâˆ’1ð”¼[X_k | â„±_k-1]_k-1Â Â Â Â a.s.
for all k âˆˆ I \ {0}, which is equivalent to saying that every term in definition (1) of A is almost surely positive, hence A is almost surely increasing. The equivalence for supermartingales is proved similarly.

Example[edit]
Let X = (Xn)nâˆˆN0â„•_0 be a sequence in independent, integrable, real-valued random variables. They are adapted to the filtration generated by the sequence, i.e. Fn = Ïƒ(X0, . . . , Xn)  for all n âˆˆ N0â„•_0. By (1) and (2), the Doob decomposition is given by

An=âˆ‘k=1n(E[Xk]âˆ’Xkâˆ’1),nâˆˆN0,_n=âˆ‘_k=1^n(ð”¼[X_k]-X_k-1),âˆˆâ„•_0,
and

Mn=X0+âˆ‘k=1n(Xkâˆ’E[Xk]),nâˆˆN0._n=X_0+âˆ‘_k=1^n(X_k-ð”¼[X_k]),âˆˆâ„•_0.
If the random variables of the original sequenceÂ X have mean zero, this simplifies to

An=âˆ’âˆ‘k=0nâˆ’1Xk_n=-âˆ‘_k=0^n-1X_kÂ Â Â Â andÂ Â Â Â Mn=âˆ‘k=0nXk,nâˆˆN0,_n=âˆ‘_k=0^nX_k,âˆˆâ„•_0,
hence both processes are (possibly time-inhomogeneous) random walks. If the sequence X = (Xn)nâˆˆN0â„•_0 consists of symmetric random variables taking the values +1 andÂ âˆ’1, then XÂ is bounded, but the martingaleÂ M and the predictable processÂ A are unbounded simple random walks (and not uniformly integrable), and Doob's optional stopping theorem might not be applicable to the martingaleÂ M unless the stopping time has a finite expectation.

Application[edit]
In mathematical finance, the Doob decomposition theorem can be used to determine the largest optimal exercise time of an American option.[6][7] Let X = (X0, X1, . . . , XN) denote the non-negative, discounted payoffs of an American option in a N-period financial market model, adapted to a filtration 
(F0, F1, . . . , FN), and let Qâ„š denote an equivalent martingale measure. Let U = (U0, U1, . . . , UN) denote the Snell envelope ofÂ X with respect to Qâ„š. The Snell envelope is the smallest Qâ„š-supermartingale dominating X[8] and in a complete financial market it represents the minimal amount of capital necessary to hedge the American option up to maturity.[9] Let U = M + A denote the Doob decomposition with respect to Qâ„š of the Snell envelopeÂ U into a martingale M = (M0, M1, . . . , MN) and a decreasing predictable process A = (A0, A1, . . . , AN) with A0 = 0. Then the largest stopping time to exercise the American option in an optimal way[10][11] is

Ï„max:=NifAN=0,minnâˆˆ0,â€¦,Nâˆ’1âˆ£An+1<0ifAN<0.Ï„_max:=N   ifA_N=0,
min{nâˆˆ{0,â€¦,N-1}_n+1<0}   ifA_N<0.
Since A is predictable, the event {Ï„max = n} = {An = 0, An+1 < 0} is inÂ Fn for every n âˆˆ {0, 1, . . . , N âˆ’ 1}, hence Ï„max is indeed a stopping time. It gives the last moment before the discounted value of the American option will drop in expectation; up to timeÂ Ï„max the discounted value processÂ U is a martingale with respect to Qâ„š.

Generalization[edit]
The Doob decomposition theorem can be generalized from probability spaces to Ïƒ-finite measure spaces.[12]

Citations[edit]


^ Doob (1953), see (Doob 1990, pp.Â 296âˆ’298)

^ Durrett (2010)

^ (FÃ¶llmer & Schied 2011, PropositionÂ 6.1)

^ (Williams 1991, SectionÂ 12.11, partÂ (a) of the Theorem)

^ (Williams 1991, SectionÂ 12.11, partÂ (b) of the Theorem)

^ (Lamberton & Lapeyre 2008, ChapterÂ 2: Optimal stopping problem and American options)

^ (FÃ¶llmer & Schied 2011, ChapterÂ 6: American contingent claims)

^ (FÃ¶llmer & Schied 2011, PropositionÂ 6.10)

^ (FÃ¶llmer & Schied 2011, TheoremÂ 6.11)

^ (Lamberton & Lapeyre 2008, PropositionÂ 2.3.2)

^ (FÃ¶llmer & Schied 2011, TheoremÂ 6.21)

^ (Schilling 2005, ProblemÂ 23.11)


References[edit]
Doob, Joseph L. (1953), Stochastic Processes, New York: Wiley, ISBNÂ 978-0-471-21813-5, MRÂ 0058896, ZblÂ 0053.26802
Doob, Joseph L. (1990), Stochastic Processes (Wiley Classics LibraryÂ ed.), New York: John Wiley & Sons, Inc., ISBNÂ 0-471-52369-0, MRÂ 1038526, ZblÂ 0696.60003
Durrett, Rick (2010), Probability: Theory and Examples, Cambridge Series in Statistical and Probabilistic Mathematics (4.Â ed.), Cambridge University Press, ISBNÂ 978-0-521-76539-8, MRÂ 2722836, ZblÂ 1202.60001
FÃ¶llmer, Hans; Schied, Alexander (2011), Stochastic Finance: An Introduction in Discrete Time, De Gruyter graduate (3. rev. and extendÂ ed.), Berlin, New York: De Gruyter, ISBNÂ 978-3-11-021804-6, MRÂ 2779313, ZblÂ 1213.91006
Lamberton, Damien; Lapeyre, Bernard (2008), Introduction to Stochastic Calculus Applied to Finance, Chapman & Hall/CRC financial mathematics series (2.Â ed.), Boca Raton, FL: Chapman & Hall/CRC, ISBNÂ 978-1-58488-626-6, MRÂ 2362458, ZblÂ 1167.60001
Schilling, RenÃ© L. (2005), Measures, Integrals and Martingales, Cambridge: Cambridge University Press, ISBNÂ 978-0-52185-015-5, MRÂ 2200059, ZblÂ 1084.28001
Williams, David (1991), Probability with Martingales, Cambridge University Press, ISBNÂ 0-521-40605-6, MRÂ 1155402, ZblÂ 0722.60001
vteStochastic processesDiscrete time
Bernoulli process
Branching process
Chinese restaurant process
Galtonâ€“Watson process
Independent and identically distributed random variables
Markov chain
Moran process
Random walk
Loop-erased
Self-avoiding
 Biased
Maximal entropy
Continuous time
Additive process
Bessel process
Birthâ€“death process
pure birth
Brownian motion
Bridge
Excursion
Fractional
Geometric
Meander
Cauchy process
Contact process
Continuous-time random walk
Cox process
Diffusion process
Empirical process
Feller process
Flemingâ€“Viot process
Gamma process
Geometric process
Hawkes process
Hunt process
Interacting particle systems
ItÃ´ diffusion
ItÃ´ process
Jump diffusion
Jump process
LÃ©vy process
Local time
Markov additive process
McKeanâ€“Vlasov process
Ornsteinâ€“Uhlenbeck process
Poisson process
Compound
Non-homogeneous
Schrammâ€“Loewner evolution
Semimartingale
Sigma-martingale
Stable process
Superprocess
Telegraph process
Variance gamma process
Wiener process
Wiener sausage
Both
Branching process
Galvesâ€“LÃ¶cherbach model
Gaussian process
Hidden Markov model (HMM)
Markov process
Martingale
Differences
Local
Sub-
Super-
Random dynamical system
Regenerative process
Renewal process
Stochastic chains with memory of variable length
White noise
Fields and other
Dirichlet process
Gaussian random field
Gibbs measure
Hopfield model
Ising model
Potts model
Boolean network
Markov random field
Percolation
Pitmanâ€“Yor process
Point process
Cox
Poisson
Random field
Random graph
Time series models
Autoregressive conditional heteroskedasticity (ARCH) model
Autoregressive integrated moving average (ARIMA) model
Autoregressive (AR) model
Autoregressiveâ€“moving-average (ARMA) model
Generalized autoregressive conditional heteroskedasticity (GARCH) model
Moving-average (MA) model
Financial models
Binomial options pricing model
Blackâ€“Dermanâ€“Toy
Blackâ€“Karasinski
Blackâ€“Scholes
Chanâ€“Karolyiâ€“Longstaffâ€“Sanders (CKLS)
Chen
Constant elasticity of variance (CEV)
Coxâ€“Ingersollâ€“Ross (CIR)
Garmanâ€“Kohlhagen
Heathâ€“Jarrowâ€“Morton (HJM)
Heston
Hoâ€“Lee
Hullâ€“White
LIBOR market
Rendlemanâ€“Bartter
SABR volatility
VaÅ¡Ã­Äek
Wilkie
Actuarial models
BÃ¼hlmann
CramÃ©râ€“Lundberg
Risk process
Sparreâ€“Anderson
Queueing models
Bulk
Fluid
Generalized queueing network
M/G/1
M/M/1
M/M/c
Properties
CÃ dlÃ g paths
Continuous
Continuous paths
Ergodic
Exchangeable
Feller-continuous
Gaussâ€“Markov
Markov
Mixing
Piecewise-deterministic
Predictable
Progressively measurable
Self-similar
Stationary
Time-reversible
Limit theorems
Central limit theorem
Donsker's theorem
Doob's martingale convergence theorems
Ergodic theorem
Fisherâ€“Tippettâ€“Gnedenko theorem
Large deviation principle
Law of large numbers (weak/strong)
Law of the iterated logarithm
Maximal ergodic theorem
Sanov's theorem
Zeroâ€“one laws (Blumenthal, Borelâ€“Cantelli, Engelbertâ€“Schmidt, Hewittâ€“Savage,  Kolmogorov, LÃ©vy)
Inequalities
Burkholderâ€“Davisâ€“Gundy
Doob's martingale
Doob's upcrossing
Kunitaâ€“Watanabe
Marcinkiewiczâ€“Zygmund
Tools
Cameronâ€“Martin formula
Convergence of random variables
DolÃ©ans-Dade exponential
Doob decomposition theorem
Doobâ€“Meyer decomposition theorem
Doob's optional stopping theorem
Dynkin's formula
Feynmanâ€“Kac formula
Filtration
Girsanov theorem
Infinitesimal generator
ItÃ´ integral
ItÃ´'s lemma
Karhunenâ€“LoÃ¨ve theorem
Kolmogorov continuity theorem
Kolmogorov extension theorem
LÃ©vyâ€“Prokhorov metric
Malliavin calculus
Martingale representation theorem
Optional stopping theorem
Prokhorov's theorem
Quadratic variation
Reflection principle
Skorokhod integral
Skorokhod's representation theorem
Skorokhod space
Snell envelope
Stochastic differential equation
Tanaka
Stopping time
Stratonovich integral
Uniform integrability
Usual hypotheses
Wiener space
Classical
Abstract
Disciplines
Actuarial mathematics
Control theory
Econometrics
Ergodic theory
Extreme value theory (EVT)
Large deviations theory
Mathematical finance
Mathematical statistics
Probability theory
Queueing theory
Renewal theory
Ruin theory
Signal processing
Statistics
Stochastic analysis
Time series analysis
Machine learning

List of topics
Category




