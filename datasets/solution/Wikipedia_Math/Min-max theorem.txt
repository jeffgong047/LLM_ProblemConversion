Variational characterization of eigenvalues of compact Hermitian operators on Hilbert spaces
Not to be confused with Minimax theorem.
"Variational theorem" redirects here. Not to be confused with variational principle.
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:Â "Min-max theorem"Â â€“Â newsÂ Â· newspapersÂ Â· booksÂ Â· scholarÂ Â· JSTOR (November 2011) (Learn how and when to remove this template message)
In linear algebra and functional analysis, the min-max theorem, or variational theorem, or Courantâ€“Fischerâ€“Weyl min-max principle, is a result that gives a variational characterization of eigenvalues of compact Hermitian operators on Hilbert spaces. It can be viewed as the starting point of many results of similar nature.
This article first discusses the finite-dimensional case and its applications before considering compact operators on infinite-dimensional Hilbert spaces. 
We will see that for compact operators, the proof of the main theorem uses essentially the same idea from the finite-dimensional argument.
In the case that the operator is non-Hermitian, the theorem provides an equivalent characterization of the associated singular values. 
The min-max theorem can be extended to self-adjoint operators that are bounded below.


Matrices[edit]
Let A be a n Ã— n Hermitian matrix. As with many other variational results on eigenvalues, one considers the Rayleighâ€“Ritz quotient RAÂ : Cn \ {0} â†’ R defined by

RA(x)=(Ax,x)(x,x)_A(x)=(Ax,x)/(x,x)
where (â‹…, â‹…) denotes the Euclidean inner product on Cn. 
Clearly, the Rayleigh quotient of an eigenvector is its associated eigenvalue. Equivalently, the Rayleighâ€“Ritz quotient can be replaced by

f(x)=(Ax,x),â€–xâ€–=1.(x)=(Ax,x), x=1.
For Hermitian matrices A, the range of the continuous function RA(x), or f(x), is a compact interval [a, b] of the real line. The maximum b and the minimum a are the largest and smallest eigenvalue of A, respectively. The min-max theorem is a refinement of this fact.

Min-max theorem[edit]
Let A be an n Ã— n Hermitian matrix with eigenvalues Î»1 â‰¤ ... â‰¤ Î»k â‰¤ ... â‰¤ Î»n, then

Î»k=minUmaxxRA(x)âˆ£xâˆˆUandxâ‰ 0âˆ£dimâ¡(U)=kÎ»_k=min_U{max_x{R_A(x)andxâ‰ 0}|(U)=k}
and

Î»k=maxUminxRA(x)âˆ£xâˆˆUandxâ‰ 0âˆ£dimâ¡(U)=nâˆ’k+1Î»_k=max_U{min_x{R_A(x)andxâ‰ 0}|(U)=n-k+1},
in particular,

âˆ€xâˆˆCnâˆ–0:Î»1â‰¤RA(x)â‰¤Î»nâˆˆğ‚^n\{0}Î»_1_A(x)â‰¤Î»_n
and these bounds are attained when x is an eigenvector of the appropriate eigenvalues.
Also the simpler formulation for the maximal eigenvalue Î»n is given by: 

Î»n=maxRA(x):xâ‰ 0.Î»_n=max{R_A(x):xâ‰ 0}.
Similarly, the minimal eigenvalue Î»1 is given by: 

Î»1=minRA(x):xâ‰ 0.Î»_1=min{R_A(x):xâ‰ 0}.
Proof
Since the matrix A is Hermitian it is diagonalizable and we can choose an orthonormal basis of eigenvectors {u1, ..., un} that is, ui is an eigenvector for the eigenvalue Î»i and such that (ui, ui) = 1 and (ui, uj) = 0 for all i â‰  j.
If U is a subspace of dimension k then its intersection with the subspace span{uk, ..., un}  isn't zero, 
for if it were, then the dimension of the span of the two subspaces would be k+(nâˆ’k+1)+(n-k+1), which is impossible. Hence there exists a vector v â‰  0 in this intersection that we can write as

v=âˆ‘i=knÎ±iui=âˆ‘_i=k^nÎ±_iu_i
and whose Rayleigh quotient is

RA(v)=âˆ‘i=knÎ»i|Î±i|2âˆ‘i=kn|Î±i|2â‰¥Î»k_A(v)=âˆ‘_i=k^nÎ»_i|Î±_i|^2/âˆ‘_i=k^n|Î±_i|^2â‰¥Î»_k
(as all Î»iâ‰¥Î»kÎ»_iâ‰¥Î»_k for i=k,..,n)
and hence

maxRA(x)âˆ£xâˆˆUâ‰¥Î»kmax{R_A(x)}â‰¥Î»_k
Since this is true for all U, we can conclude that 

minmaxRA(x)âˆ£xâˆˆUandxâ‰ 0âˆ£dimâ¡(U)=kâ‰¥Î»kmin{max{R_A(x)andxâ‰ 0}|(U)=k}â‰¥Î»_k
This is one inequality. To establish the other inequality, choose the specific k-dimensional space
V = span{u1, ..., uk} , for which

maxRA(x)âˆ£xâˆˆVandxâ‰ 0â‰¤Î»kmax{R_A(x)andxâ‰ 0}â‰¤Î»_k
because Î»kÎ»_k is the largest eigenvalue in V. Therefore, also

minmaxRA(x)âˆ£xâˆˆUandxâ‰ 0âˆ£dimâ¡(U)=kâ‰¤Î»kmin{max{R_A(x)andxâ‰ 0}|(U)=k}â‰¤Î»_k
To get the other formula, consider the Hermitian matrix Aâ€²=âˆ’A'=-A, whose eigenvalues in increasing order are Î»kâ€²=âˆ’Î»nâˆ’k+1Î»'_k=-Î»_n-k+1.
Applying the result just proved,

âˆ’Î»nâˆ’k+1=Î»kâ€²=minmaxRAâ€²(x)âˆ£xâˆˆUâˆ£dimâ¡(U)=k=minmaxâˆ’RA(x)âˆ£xâˆˆUâˆ£dimâ¡(U)=k=âˆ’maxminRA(x)âˆ£xâˆˆUâˆ£dimâ¡(U)=k-Î»_n-k+1=Î»'_k   =min{max{R_A'(x)}|(U)=k}
   =min{max{-R_A(x)}|(U)=k}
   =-max{min{R_A(x)}|(U)=k}
The result follows on replacing k with nâˆ’k+1-k+1.


Counterexample in the non-Hermitian case[edit]
Let N be the nilpotent matrix

[0100].[ 0 1; 0 0 ].
Define the Rayleigh quotient RN(x)_N(x) exactly as above in the Hermitian case. Then it is easy to see that the only eigenvalue of N is zero, while the maximum value of the Rayleigh quotient is 1/2. That is, the maximum value of the Rayleigh quotient is larger than the maximum eigenvalue.

Applications[edit]
Min-max principle for singular values[edit]
The singular values {Ïƒk} of a square matrix M are the square roots of the eigenvalues of M*M (equivalently MM*). An immediate consequence[citation needed] of the first equality in the min-max theorem is:

Ïƒkâ†‘=minS:dimâ¡(S)=kmaxxâˆˆS,â€–xâ€–=1(Mâˆ—Mx,x)12=minS:dimâ¡(S)=kmaxxâˆˆS,â€–xâ€–=1â€–Mxâ€–.Ïƒ_k^â†‘=min_S:(S)=kmax_x,x=1(M^*Mx,x)^1/2=min_S:(S)=kmax_x,x=1Mx.
Similarly,

Ïƒkâ†‘=maxS:dimâ¡(S)=nâˆ’k+1minxâˆˆS,â€–xâ€–=1â€–Mxâ€–.Ïƒ_k^â†‘=max_S:(S)=n-k+1min_x,x=1Mx.
Here Ïƒk=Ïƒkâ†‘Ïƒ_k=Ïƒ_k^â†‘ denotes the kth entry in the increasing sequence of Ïƒ's, so that Ïƒ1â‰¤Ïƒ2â‰¤â‹¯Ïƒ_1â‰¤Ïƒ_2â‰¤â‹¯.

Cauchy interlacing theorem[edit]
Main article: PoincarÃ© separation theorem
Let A be a symmetric n Ã— n matrix. The m Ã— m matrix B, where m â‰¤ n, is called a compression of A if there exists an orthogonal projection P onto a subspace of dimension m such that PAP* = B. The Cauchy interlacing theorem states:

Theorem. If the eigenvalues of A are Î±1 â‰¤ ... â‰¤ Î±n, and those of B are Î²1 â‰¤ ... â‰¤ Î²j â‰¤ ... â‰¤ Î²m, then for all j â‰¤ m,
Î±jâ‰¤Î²jâ‰¤Î±nâˆ’m+j.Î±_jâ‰¤Î²_jâ‰¤Î±_n-m+j.
This can be proven using the min-max principle. Let Î²i have corresponding eigenvector bi and Sj be the j dimensional subspace Sj = span{b1, ..., bj}, then

Î²j=maxxâˆˆSj,â€–xâ€–=1(Bx,x)=maxxâˆˆSj,â€–xâ€–=1(PAPâˆ—x,x)â‰¥minSjmaxxâˆˆSj,â€–xâ€–=1(A(Pâˆ—x),Pâˆ—x)=Î±j.Î²_j=max_x_j,x=1(Bx,x)=max_x_j,x=1(PAP^*x,x)â‰¥min_S_jmax_x_j,x=1(A(P^*x),P^*x)=Î±_j.
According to first part of min-max, Î±j â‰¤ Î²j. On the other hand, if we define Smâˆ’j+1 = span{bj, ..., bm}, then

Î²j=minxâˆˆSmâˆ’j+1,â€–xâ€–=1(Bx,x)=minxâˆˆSmâˆ’j+1,â€–xâ€–=1(PAPâˆ—x,x)=minxâˆˆSmâˆ’j+1,â€–xâ€–=1(A(Pâˆ—x),Pâˆ—x)â‰¤Î±nâˆ’m+j,Î²_j=min_x_m-j+1,x=1(Bx,x)=min_x_m-j+1,x=1(PAP^*x,x)=min_x_m-j+1,x=1(A(P^*x),P^*x)â‰¤Î±_n-m+j,
where the last inequality is given by the second part of min-max.
When n âˆ’ m = 1, we have Î±j â‰¤ Î²j â‰¤ Î±j+1, hence the name interlacing theorem.

Compact operators[edit]
Let A be a compact, Hermitian operator on a Hilbert space H. Recall that the spectrum of such an operator (the set of eigenvalues) is a set of real numbers whose only possible cluster point is zero. 
It is thus convenient to list the positive eigenvalues of A as

â‹¯â‰¤Î»kâ‰¤â‹¯â‰¤Î»1,â‹¯â‰¤Î»_kâ‰¤â‹¯â‰¤Î»_1,
where entries are repeated with multiplicity, as in the matrix case. (To emphasize that the sequence is decreasing, we may write Î»k=Î»kâ†“Î»_k=Î»_k^â†“.) 
When H is infinite-dimensional, the above sequence of eigenvalues is necessarily infinite. 
We now apply the same reasoning as in the matrix case. Letting Sk âŠ‚ H be a k dimensional subspace, we can obtain the following theorem.

Theorem (Min-Max). Let A be a compact, self-adjoint operator on a Hilbert space H, whose positive eigenvalues are listed in decreasing order ... â‰¤ Î»k â‰¤ ... â‰¤ Î»1. Then:
maxSkminxâˆˆSk,â€–xâ€–=1(Ax,x)=Î»kâ†“,minSkâˆ’1maxxâˆˆSkâˆ’1âŠ¥,â€–xâ€–=1(Ax,x)=Î»kâ†“.max_S_kmin_x_k,x=1(Ax,x)   =Î»_k^â†“,
min_S_k-1max_x_k-1^âŠ¥,x=1(Ax,x)   =Î»_k^â†“.
A similar pair of equalities hold for negative eigenvalues.

Proof
Let S'  be the closure of the linear span Sâ€²=spanâ¡uk,uk+1,â€¦'=span{u_k,u_k+1,â€¦}.
The subspace S'  has codimension k âˆ’ 1. By the same dimension count argument as in the matrix case, S'  âˆ© Sk has positive dimension. So there exists x âˆˆ S'Â  âˆ© Sk with â€–xâ€–=1x=1. Since it is an element of S' , such an x necessarily satisfy

(Ax,x)â‰¤Î»k.(Ax,x)â‰¤Î»_k.
Therefore, for all Sk

infxâˆˆSk,â€–xâ€–=1(Ax,x)â‰¤Î»kinf_x_k,x=1(Ax,x)â‰¤Î»_k
But A is compact, therefore the function f(x) = (Ax, x) is weakly continuous. Furthermore, any bounded set in H is weakly compact. This lets us replace the infimum by minimum:

minxâˆˆSk,â€–xâ€–=1(Ax,x)â‰¤Î»k.min_x_k,x=1(Ax,x)â‰¤Î»_k.
So

supSkminxâˆˆSk,â€–xâ€–=1(Ax,x)â‰¤Î»k.sup_S_kmin_x_k,x=1(Ax,x)â‰¤Î»_k.
Because equality is achieved when Sk=spanâ¡u1,â€¦,uk_k=span{u_1,â€¦,u_k},

maxSkminxâˆˆSk,â€–xâ€–=1(Ax,x)=Î»k.max_S_kmin_x_k,x=1(Ax,x)=Î»_k.
This is the first part of min-max theorem for compact self-adjoint operators.
Analogously, consider now a (k âˆ’ 1)-dimensional subspace Skâˆ’1, whose the orthogonal complement is denoted by Skâˆ’1âŠ¥. If S'  =Â span{u1...uk},

Sâ€²âˆ©Skâˆ’1âŠ¥â‰ 0.'_k-1^âŠ¥â‰ 0.
So

âˆƒxâˆˆSkâˆ’1âŠ¥â€–xâ€–=1,(Ax,x)â‰¥Î»k._k-1^âŠ¥ x=1,(Ax,x)â‰¥Î»_k.
This implies

maxxâˆˆSkâˆ’1âŠ¥,â€–xâ€–=1(Ax,x)â‰¥Î»kmax_x_k-1^âŠ¥,x=1(Ax,x)â‰¥Î»_k
where the compactness of A was applied. Index the above by the collection of k-1-dimensional subspaces gives

infSkâˆ’1maxxâˆˆSkâˆ’1âŠ¥,â€–xâ€–=1(Ax,x)â‰¥Î»k.inf_S_k-1max_x_k-1^âŠ¥,x=1(Ax,x)â‰¥Î»_k.
Pick Skâˆ’1 = span{u1, ..., ukâˆ’1} and we deduce

minSkâˆ’1maxxâˆˆSkâˆ’1âŠ¥,â€–xâ€–=1(Ax,x)=Î»k.min_S_k-1max_x_k-1^âŠ¥,x=1(Ax,x)=Î»_k.

Self-adjoint operators[edit]
The min-max theorem also applies to (possibly unbounded) self-adjoint operators.[1][2] Recall the essential spectrum is the spectrum without isolated eigenvalues of finite multiplicity. 
Sometimes we have some eigenvalues below the essential spectrum, and we would like to approximate the eigenvalues and eigenfunctions.

Theorem (Min-Max). Let A be self-adjoint, and let E1â‰¤E2â‰¤E3â‰¤â‹¯_1_2_3â‰¤â‹¯ be the eigenvalues of A below the essential spectrum. Then
En=minÏˆ1,â€¦,ÏˆnmaxâŸ¨Ïˆ,AÏˆâŸ©:Ïˆâˆˆspanâ¡(Ïˆ1,â€¦,Ïˆn),â€–Ïˆâ€–=1_n=min_Ïˆ_1,â€¦,Ïˆ_nmax{âŸ¨Ïˆ,AÏˆâŸ©:Ïˆâˆˆspan(Ïˆ_1,â€¦,Ïˆ_n), Ïˆ=1}.
If we only have N eigenvalues and hence run out of eigenvalues, then we let En:=infÏƒess(A)_n:=infÏƒ_ess(A) (the bottom of the essential spectrum) for n>N, and the above statement holds after replacing min-max with inf-sup.

Theorem (Max-Min). Let A be self-adjoint, and let E1â‰¤E2â‰¤E3â‰¤â‹¯_1_2_3â‰¤â‹¯ be the eigenvalues of A below the essential spectrum. Then
En=maxÏˆ1,â€¦,Ïˆnâˆ’1minâŸ¨Ïˆ,AÏˆâŸ©:ÏˆâŠ¥Ïˆ1,â€¦,Ïˆnâˆ’1,â€–Ïˆâ€–=1_n=max_Ïˆ_1,â€¦,Ïˆ_n-1min{âŸ¨Ïˆ,AÏˆâŸ©:ÏˆâŠ¥Ïˆ_1,â€¦,Ïˆ_n-1, Ïˆ=1}.
If we only have N eigenvalues and hence run out of eigenvalues, then we let En:=infÏƒess(A)_n:=infÏƒ_ess(A) (the bottom of the essential spectrum) for n > N, and the above statement holds after replacing max-min with sup-inf.
The proofs[1][2] use the following results about self-adjoint operators:

Theorem. Let A be self-adjoint. Then (Aâˆ’E)â‰¥0(A-E)â‰¥0 for EâˆˆRâˆˆâ„ if and only if Ïƒ(A)âŠ†[E,âˆ)Ïƒ(A)âŠ†[E,âˆ).[1]:â€Š77â€Š
Theorem. If A is self-adjoint, then
infÏƒ(A)=infÏˆâˆˆD(A),â€–Ïˆâ€–=1âŸ¨Ïˆ,AÏˆâŸ©infÏƒ(A)=inf_Ïˆâˆˆğ”‡(A),Ïˆ=1âŸ¨Ïˆ,AÏˆâŸ©
and
supÏƒ(A)=supÏˆâˆˆD(A),â€–Ïˆâ€–=1âŸ¨Ïˆ,AÏˆâŸ©supÏƒ(A)=sup_Ïˆâˆˆğ”‡(A),Ïˆ=1âŸ¨Ïˆ,AÏˆâŸ©.[1]:â€Š77â€Š

See also[edit]
Courant minimax principle
Maxâ€“min inequality
References[edit]


^ a b c d G. Teschl, Mathematical Methods in Quantum Mechanics (GSM 99) https://www.mat.univie.ac.at/~gerald/ftp/book-schroe/schroe.pdf

^ a b Lieb; Loss (2001). Analysis. GSM. Vol.Â 14 (2ndÂ ed.). Providence: American Mathematical Society. ISBNÂ 0-8218-2783-9.


External links and citations to related work[edit]
Fisk, Steve (2005). "A very short proof of Cauchy's interlace theorem for eigenvalues of Hermitian matrices". arXiv:math/0502408. {{cite journal}}: Cite journal requires |journal= (help)
Hwang, Suk-Geun (2004). "Cauchy's Interlace Theorem for Eigenvalues of Hermitian Matrices". The American Mathematical Monthly. 111 (2): 157â€“159. doi:10.2307/4145217. JSTORÂ 4145217.
Kline, Jeffery (2020). "Bordered Hermitian matrices and sums of the MÃ¶bius function". Linear Algebra and Its Applications. 588: 224â€“237. doi:10.1016/j.laa.2019.12.004.
Reed, Michael; Simon, Barry (1978). Methods of Modern Mathematical Physics IV: Analysis of Operators. Academic Press. ISBNÂ 978-0-08-057045-7.
vteFunctional analysisÂ (topics â€“ glossary)Spaces
Banach
Besov
FrÃ©chet
Hilbert
HÃ¶lder
Nuclear
Orlicz
Schwartz
Sobolev
Topological vector
Properties
Barrelled
Complete
Dual (Algebraic/Topological)
Locally convex
Reflexive
Separable
Theorems
Hahnâ€“Banach
Riesz representation
Closed graph
Uniform boundedness principle
Kakutani fixed-point
Kreinâ€“Milman
Minâ€“max
Gelfandâ€“Naimark
Banachâ€“Alaoglu
Operators
Adjoint
Bounded
Compact
Hilbertâ€“Schmidt
Normal
Nuclear
Trace class
Transpose
Unbounded
Unitary
Algebras
Banach algebra
C*-algebra
Spectrum of a C*-algebra
Operator algebra
Group algebra of a locally compact group
Von Neumann algebra
Open problems
Invariant subspace problem
Mahler's conjecture
Applications
Hardy space
Spectral theory of ordinary differential equations
Heat kernel
Index theorem
Calculus of variations
Functional calculus
Integral operator
Jones polynomial
Topological quantum field theory
Noncommutative geometry
Riemann hypothesis
Distribution (or Generalized functions)
Advanced topics
Approximation property
Balanced set
Choquet theory
Weak topology
Banachâ€“Mazur distance
Tomitaâ€“Takesaki theory

Â Mathematics portal
 Category
Commons

vteAnalysis in topological vector spacesBasic concepts
Abstract Wiener space
Classical Wiener space
Bochner space
Convex series
Cylinder set measure
Infinite-dimensional vector function
Matrix calculus
Vector calculus
Derivatives
Differentiable vectorâ€“valued functions from Euclidean space
Differentiation in FrÃ©chet spaces
FrÃ©chet derivative
Total
Functional derivative
Gateaux derivative
Directional
Generalizations of the derivative
Hadamard derivative
Holomorphic
Quasi-derivative
Measurability
Besov measure
Cylinder set measure
Canonical Gaussian
Classical Wiener measure
MeasureÂ likeÂ set functions
infinite-dimensional Gaussian measure
Projection-valued
Vector
Bochner / Weakly / Strongly measurable function
Radonifying function
Integrals
Bochner
Direct integral
Dunford
Gelfandâ€“Pettis/Weak
Regulated
Paleyâ€“Wiener
Results
Cameronâ€“Martin theorem
Inverse function theorem
Nashâ€“Moser theorem
Feldmanâ€“HÃ¡jek theorem
No infinite-dimensional Lebesgue measure
Sazonov's theorem
Structure theorem for Gaussian measures
Related
Crinkled arc
Covariance operator
Functional calculus
Borel functional calculus
Continuous functional calculus
Holomorphic functional calculus
Applications
Banach manifoldÂ (bundle)
Convenient vector space
Choquet theory
FrÃ©chet manifold
Hilbert manifold

vteSpectral theory and *-algebrasBasic concepts
Involution/*-algebra
Banach algebra
B*-algebra
C*-algebra
Noncommutative topology
Projection-valued measure
Spectrum
Spectrum of a C*-algebra
Spectral radius
Operator space
Main results
Gelfandâ€“Mazur theorem
Gelfandâ€“Naimark theorem
Gelfand representation
Polar decomposition
Singular value decomposition
Spectral theorem
Spectral theory of normal C*-algebras
Special Elements/Operators
Isospectral
Normal operator
Hermitian/Self-adjoint operator
Unitary operator
Unit
Spectrum
Kreinâ€“Rutman theorem
Normal eigenvalue
Spectrum of a C*-algebra
Spectral radius
Spectral asymmetry
Spectral gap
Decomposition
Decomposition of a spectrum
Continuous
Point
Residual
Approximate point
Compression
Direct integral
Discrete
Spectral abscissa
Spectral Theorem
Borel functional calculus
Min-max theorem
Positive operator-valued measure
Projection-valued measure
Riesz projector
Rigged Hilbert space
Spectral theorem
Spectral theory of compact operators
Spectral theory of normal C*-algebras
Special algebras
Amenable Banach algebra
With an Approximate identity
Banach function algebra
Disk algebra
Nuclear C*-algebra
Uniform algebra
Von Neumann algebra
Tomitaâ€“Takesaki theory
Finite-Dimensional
Alonâ€“Boppana bound
Bauerâ€“Fike theorem
Numerical range
Schurâ€“Horn theorem
Generalizations
Dirac spectrum
Essential spectrum
Pseudospectrum
Structure space (Shilov boundary)
Miscellaneous
Abstract index group
Banach algebra cohomology
Cohenâ€“Hewitt factorization theorem
Extensions of symmetric operators
Fredholm theory
Limiting absorption principle
SchrÃ¶derâ€“Bernstein theorems for operator algebras
Shermanâ€“Takeda theorem
Unbounded operator
Examples
Wiener algebra
Applications
Almost Mathieu operator
Corona theorem
Hearing the shape of a drum (Dirichlet eigenvalue)
Heat kernel
Kuznetsov trace formula
Lax pair
Proto-value function
Ramanujan graph
Rayleighâ€“Faberâ€“Krahn inequality
Spectral geometry
Spectral method
Spectral theory of ordinary differential equations
Sturmâ€“Liouville theory
Superstrong approximation
Transfer operator
Transform theory
Weyl law
Wienerâ€“Khinchin theorem




