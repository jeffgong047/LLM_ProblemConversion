Not to be confused with the contraction mapping theorem.
In probability theory, the continuous mapping theorem states that continuous functions preserve limits even if their arguments are sequences of random variables. A continuous function, in Heineâ€™s definition, is such a function that maps convergent sequences into convergent sequences: if xn â†’ x then g(xn) â†’ g(x). The continuous mapping theorem states that this will also be true if we replace the deterministic sequence {xn} with a sequence of random variables {Xn}, and replace the standard notion of convergence of real numbers â€œâ†’â€ with one of the types of convergence of random variables.
This theorem was first proved by Henry Mann and Abraham Wald in 1943,[1] and it is therefore sometimes called the Mannâ€“Wald theorem.[2] Meanwhile, Denis Sargan refers to it as the general transformation theorem.[3]


Statement[edit]
Let {Xn}, X be random elements defined on a metric space S. Suppose a function g: Sâ†’Sâ€² (where Sâ€² is another metric space) has the set of discontinuity points Dg such that Pr[Xâ€‰âˆˆâ€‰Dg] = 0. Then[4][5]

Xnâ†’dXâ‡’g(Xn)â†’dg(X);Xnâ†’pXâ‡’g(Xn)â†’pg(X);Xnâ†’a.s.Xâ‡’g(Xn)â†’a.s.g(X).X_n{     â‡’(X_n){(X);
X_n{     â‡’(X_n){(X);
X_n{     â‡’(X_n){(X).
where the superscripts, "d", "p", and "a.s." denote convergence in distribution, convergence in probability, and almost sure convergence respectively.

Proof[edit]
This proof has been adopted from (van der Vaart 1998, Theorem 2.3)
Spaces S and Sâ€² are equipped with certain metrics. For simplicity we will denote both of these metrics using the |xÂ âˆ’Â y| notation, even though the metrics may be arbitrary and not necessarily Euclidean.

Convergence in distribution[edit]
We will need a particular statement from the portmanteau theorem: that convergence in distribution Xnâ†’dX_nX is equivalent to

Ef(Xn)â†’Ef(X)ð”¼f(X_n)â†’ð”¼f(X) for every bounded continuous functional f.
So it suffices to prove that Ef(g(Xn))â†’Ef(g(X))ð”¼f(g(X_n))â†’ð”¼f(g(X)) for every bounded continuous functional f. Note that F=fâˆ˜g=f is itself a bounded continuous functional. And so the claim follows from the statement above.

Convergence in probability[edit]
Fix an arbitrary ÎµÂ >Â 0. Then for any Î´Â >Â 0 consider the set BÎ´ defined as

BÎ´=xâˆˆSâˆ£xâˆ‰Dg:âˆƒyâˆˆS:|xâˆ’y|<Î´,|g(x)âˆ’g(y)|>Îµ._Î´={x_g:
existsy:x-y|<Î´, |g(x)-g(y)|>Îµ}.
This is the set of continuity points x of the function g(Â·) for which it is possible to find, within the Î´-neighborhood of x, a point which maps outside the Îµ-neighborhood of g(x). By definition of continuity, this set shrinks as Î´ goes to zero, so that limÎ´Â â†’Â 0BÎ´Â =Â âˆ….
Now suppose that |g(X)Â âˆ’Â g(Xn)|Â >Â Îµ. This implies that at least one of the following is true: either |Xâˆ’Xn|Â â‰¥Â Î´, or XÂ âˆˆÂ Dg, or XâˆˆBÎ´. In terms of probabilities this can be written as

Pr(|g(Xn)âˆ’g(X)|>Îµ)â‰¤Pr(|Xnâˆ’X|â‰¥Î´)+Pr(XâˆˆBÎ´)+Pr(XâˆˆDg).(|g(X_n)-g(X)|>Îµ)â‰¤(|X_n-X|â‰¥Î´)+(X_Î´)+(X_g).
On the right-hand side, the first term converges to zero as nÂ â†’Â âˆž for any fixed Î´, by the definition of convergence in probability of the sequence {Xn}. The second term converges to zero as Î´Â â†’Â 0, since the set BÎ´ shrinks to an empty set. And the last term is identically equal to zero by assumption of the theorem. Therefore, the conclusion is that

limnâ†’âˆžPr(|g(Xn)âˆ’g(X)|>Îµ)=0,lim_nâ†’âˆž(|g(X_n)-g(X)|>Îµ)=0,
which means that g(Xn) converges to g(X) in probability.

Almost sure convergence[edit]
By definition of the continuity of the function g(Â·),

limnâ†’âˆžXn(Ï‰)=X(Ï‰)â‡’limnâ†’âˆžg(Xn(Ï‰))=g(X(Ï‰))lim_nâ†’âˆžX_n(Ï‰)=X(Ï‰)  â‡’  lim_nâ†’âˆžg(X_n(Ï‰))=g(X(Ï‰))
at each point X(Ï‰) where g(Â·) is continuous. Therefore,

Pr(limnâ†’âˆžg(Xn)=g(X))â‰¥Pr(limnâ†’âˆžg(Xn)=g(X),Xâˆ‰Dg)â‰¥Pr(limnâ†’âˆžXn=X,Xâˆ‰Dg)=1,(lim_nâ†’âˆžg(X_n)=g(X))   â‰¥(lim_nâ†’âˆžg(X_n)=g(X),_g)
   â‰¥(lim_nâ†’âˆžX_n=X,_g)=1,
because the intersection of two almost sure events is almost sure.
By definition, we conclude that g(Xn) converges to g(X) almost surely.

See also[edit]
Slutsky's theorem
Portmanteau theorem
Pushforward measure
References[edit]


^ Mann, H. B.; Wald, A. (1943). "On Stochastic Limit and Order Relationships". Annals of Mathematical Statistics. 14 (3): 217â€“226. doi:10.1214/aoms/1177731415. JSTORÂ 2235800.

^ Amemiya, Takeshi (1985). Advanced Econometrics. Cambridge, MA: Harvard University Press. p.Â 88. ISBNÂ 0-674-00560-0.

^ Sargan, Denis (1988). Lectures on Advanced Econometric Theory. Oxford: Basil Blackwell. pp.Â 4â€“8. ISBNÂ 0-631-14956-2.

^ Billingsley, Patrick (1969). Convergence of Probability Measures. John Wiley & Sons. p.Â 31 (Corollary 1). ISBNÂ 0-471-07242-7.

^ van der Vaart, A. W. (1998). Asymptotic Statistics. New York: Cambridge University Press. p.Â 7 (Theorem 2.3). ISBNÂ 0-521-49603-9.





