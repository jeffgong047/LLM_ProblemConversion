Example: Phone calls arrive at a switchboard according to a Poisson process at an average rate of λ per minute. This rate is not observable, but the numbers X1, ..., Xn of phone calls that arrived during n successive one-minute periods are observed. It is desired to estimate the probability e−λ that the next one-minute period passes with no phone calls. An extremely crude estimator of the desired probability is δ0=1ifX1=0,0otherwise,δ_0={1 if_1=0, 0 otherwise,. i.e., it estimates this probability to be 1 if no phone calls arrived in the first minute and zero otherwise. Despite the apparent limitations of this estimator, the result given by its Rao–Blackwellization is a very good estimator. The sum Sn=∑i=1nXi=X1+⋯+Xn_n=∑_i=1^nX_i=X_1+⋯+X_n can be readily shown to be a sufficient statistic for λ, i.e., the conditional distribution of the data X1, ..., Xn, depends on λ only through this sum. Therefore, we find the Rao–Blackwell estimator δ1=E⁡(δ0∣Sn=sn).δ_1=E(δ_0_n=s_n). After doing some algebra we have δ1=E⁡(1X1=0|∑i=1nXi=sn)=P(X1=0|∑i=1nXi=sn)=P(X1=0,∑i=2nXi=sn)×P(∑i=1nXi=sn)−1=e−λ((n−1)λ)sne−(n−1)λsn!×((nλ)sne−nλsn!)−1=((n−1)λ)sne−nλsn!×sn!(nλ)sne−nλ=(1−1n)snδ_1 =E(1_{X_1=0}|∑_i=1^nX_i=s_n) =P(X_1=0|∑_i=1^nX_i=s_n) =P(X_1=0,∑_i=2^nX_i=s_n)(∑_i=1^nX_i=s_n)^-1 =e^-λ((n-1)λ)^s_ne^-(n-1)λ/s_n!×((nλ)^s_ne^-nλ/s_n!)^-1 =((n-1)λ)^s_ne^-nλ/s_n!×s_n!/(nλ)^s_ne^-nλ =(1-1/n)^s_n Since the average number of calls arriving during the first n minutes is nλ, one might not be surprised if this estimator has a fairly high probability (if n is big) of being close to (1−1n)nλ≈e−λ.(1-1)^nλ^-λ. So δ1 is clearly a very much improved estimator of that last quantity. In fact, since Sn is complete and δ0 is unbiased, δ1 is the unique minimum variance unbiased estimator by the Lehmann–Scheffé theorem.