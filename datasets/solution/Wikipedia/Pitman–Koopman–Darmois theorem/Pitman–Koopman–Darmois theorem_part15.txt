distributions: The following table shows how to rewrite a number of common distributions as exponential-family distributions with natural parameters. Refer to the flashcards[12] for main exponential families. For a scalar variable and scalar parameter, the form is as follows: fX(x∣θ)=h(x)exp⁡(η(θ)T(x)−A(η))_X(x|θ)=h(x)exp(η(θ)T(x)-A(η)) For a scalar variable and vector parameter: fX(x∣θ)=h(x)exp⁡(η(θ)⋅T(x)−A(η))_X(x|θ)=h(x)exp(η(θ)·𝐓(x)-A(η)) fX(x∣θ)=h(x)g(θ)exp⁡(η(θ)⋅T(x))_X(x|θ)=h(x)g(θ)exp(η(θ)·𝐓(x)) For a vector variable and vector parameter: fX(x∣θ)=h(x)exp⁡(η(θ)⋅T(x)−A(η))_X(𝐱|θ)=h(𝐱)exp(η(θ)·𝐓(𝐱)-A(η)) The above formulas choose the functional form of the exponential-family with a log-partition function A(η)(η). The reason for this is so that the moments of the sufficient statistics can be calculated easily, simply by differentiating this function. Alternative forms involve either parameterizing this function in terms of the normal parameter θθ instead of the natural parameter, and/or using a factor g(η)(η) outside of the exponential. The relation between the latter and the former is: A(η)=−log⁡g(η)(η)=-(η) g(η)=e−A(η)(η)=e^-A(η) To convert between the representations involving the two types of parameter, use the formulas below for writing one type of parameter in terms of the other. Distribution Parameter(s) θθ Natural parameter(s) ηη Inverse parameter mapping Base measure h(x)(x) Sufficient statistic T(x)(x) Log-partition A(η)(η) Log-partition A(θ)(θ) Bernoulli distribution p log⁡p1−plogp/1-p This is the logit function. 11+e−η=eη1+eη1/1+e^-η=e^η/1+e^η This is the logistic function. 11 x log⁡(1+eη)log(1+e^η) −log⁡(1−p)-log(1-p) binomial distributionwith known number of trials n p log⁡p1−plogp/1-p 11+e−η=eη1+eη1/1+e^-η=e^η/1+e^η (nx)n x nlog⁡(1+eη)log(1+e^η) −nlog⁡(1−p)-nlog(1-p) Poisson distribution λλ log⁡λlogλ eη^η 1x!1/x! x eη^η λλ negative binomial distributionwith known number of failures r p log⁡p eη^η (x+r−1x)x+r-1 x −rlog⁡(1−eη)-rlog(1-e^η) −rlog⁡(1−p)-rlog(1-p) exponential distribution λλ −λ-λ −η-η 11 x −log⁡(−η)-log(-η) −log⁡λ-logλ Pareto distributionwith known minimum value xm_m αα −α−1-α-1 −1−η-1-η 11 log⁡x −log⁡(−1−η)+(1+η)log⁡xm-log(-1-η)+(1+η)_m −log⁡α−αlog⁡xm-logα-α_m Weibull distributionwith known shape k λλ −1λk-1/λ^k (−η)−1/k(-η)^-1/k xk−1^k-1 xk^k −log⁡(−η)−log⁡k-log(-η)- klog⁡λ−log⁡klogλ- Laplace distributionwith known mean μμ b −1b-1/b −1η-1/η 11 |x−μ||x-μ| log⁡(−2η)log(-2/η) log⁡2blog2b chi-squared distribution νν ν2−1ν/2-1 2(η+1)2(η+1) e−x/2^-x/2 log⁡x log⁡Γ(η+1)+(η+1)log⁡2logΓ(η+1)+(η+1)log2 log⁡Γ(ν2)+ν2log⁡2logΓ(ν/2)+ν/2log2 normal distributionknown variance μμ μσμ/σ σηση e−x2/(2σ2)2πσe^-x^2/(2σ^2)/√(2π)σ xσx/σ η22η^2/2 μ22σ2μ^2/2σ^2 continuous Bernoulli distribution λλ log⁡λ1−λlogλ/1-λ eη1+eηe^η/1+e^η 11 x log⁡eη−1ηloge^η-1/η log⁡(1−2λ(1−λ)log⁡(1−λλ))log(1-2λ/(1-λ)log(1-λ/λ)) normal distribution μ,σ2μ, sigma^2 [μσ2−12σ2][ μσ^2; -12σ^2 ] [−η12η2−12η2][ -η_12η_2; -12η_2 ] 12π1/√(2π) [xx2][ x; x^2 ] −η124η2−12log⁡(−2η2)-η_1^2/4η_2-1/2log(-2η_2) μ22σ2+log⁡σμ^2/2σ^2+logσ log-normal distribution μ,σ2μ, sigma^2 [μσ2−12σ2][ μσ^2; -12σ^2 ] [−η12η2−12η2][ -η_12η_2; -12η_2 ] 12πx1/√(2π)x [log⁡x(log⁡x)2][ ; ()^2 ] −η124η2−12log⁡(−2η2)-η_1^2/4η_2-1/2log(-2η_2) μ22σ2+log⁡σμ^2/2σ^2+logσ inverse Gaussian distribution μ,λμ, lambda [−λ2μ2−λ2][ -λ2μ^2; -λ2 ] [η2η1−2η2][ √(η_2η_1); -2η_2 ] 12πx3/21/√(2π)x^3/2 [x1x][ x; 1x ] −2η1η2−12log⁡(−2η2)-2√(η_1η_2)-1/2log(-2η_2) −λμ−12log⁡λ-λ/μ-1/2logλ gamma distribution α,βα, beta [α−1−β][ α-1; -β ] [η1+1−η2][ η_1+1; -η_2 ] 11 [log⁡xx][ ; x ] log⁡Γ(η1+1)−(η1+1)log⁡(−η2)logΓ(η_1+1)-(η_1+1)log(-η_2) log⁡Γ(α)−αlog⁡βlogΓ(α)-αlogβ k,θ, theta [k−1−1θ][ k-1; -1θ ] [η1+1−1η2][ η_1+1; -1η_2 ] log⁡Γ(k)+klog⁡θlogΓ(k)+klogθ inverse gamma distribution α,βα, beta [−α−1−β][ -α-1; -β ] [−η1−1−η2][ -η_1-1; -η_2 ] 11 [log⁡x1x][ ; 1/x ] log⁡Γ(−η1−1)−(−η1−1)log⁡(−η2)logΓ(-η_1-1)-(-η_1-1)log(-η_2) log⁡Γ(α)−αlog⁡βlogΓ(α)-αlogβ generalized inverse Gaussian distribution p,a,b,, [p−1−a/2−b/2][ p-1; -a/2; -b/2 ] [η1+1−2η2−2η3][ η_1+1; -2η_2; -2η_3 ] 11 [log⁡xx1x][ ; x; 1/x ] log⁡2Kη1+1(4η2η3)−η1+12log⁡η2η3log2K_η_1+1(√(4η_2η_3))-η_1+1/2logη_2/η_3 log⁡2Kp(ab)−p2log⁡ablog2K_p(√(ab))-p/2loga/b scaled inverse chi-squared distribution ν,σ2ν, sigma^2 [−ν2−1−νσ22][ -ν2-1; -νσ^22 ] [−2(η1+1)η2η1+1][ -2(η_1+1); η_2η_1+1 ] 11 [log⁡x1x][ ; 1/x ] log⁡Γ(−η1−1)−(−η1−1)log⁡(−η2)logΓ(-η_1-1)-(-η_1-1)log(-η_2) log⁡Γ(ν2)−ν2log⁡νσ22logΓ(ν/2)-ν/2logνσ^2/2 beta distribution(variant 1) α,βα, beta [αβ][ α; β ] [η1η2][ η_1; η_2 ] 1x(1−x)1/x(1-x) [log⁡xlog⁡(1−x)][ ; log(1-x) ] log⁡Γ(η1)+log⁡Γ(η2)−log⁡Γ(η1+η2)logΓ(η_1)+logΓ(η_2)-logΓ(η_1+η_2) log⁡Γ(α)+log⁡Γ(β)−log⁡Γ(α+β)logΓ(α)+logΓ(β)-logΓ(α+β) beta distribution(variant 2) α,βα, beta [α−1β−1][ α-1; β-1 ] [η1+1η2+1][ η_1+1; η_2+1 ] 11 [log⁡xlog⁡(1−x)][ ; log(1-x) ] log⁡Γ(η1+1)+log⁡Γ(η2+1)−log⁡Γ(η1+η2+2)logΓ(η_1+1)+logΓ(η_2+1)-logΓ(η_1+η_2+2) log⁡Γ(α)+log⁡Γ(β)−log⁡Γ(α+β)logΓ(α)+logΓ(β)-logΓ(α+β) multivariate normal distribution μ,Σμ,{Σ [Σ−1μ−12Σ−1][ Σ^-1μ; -1/2Σ^-1 ] [−12η2−1η1−12η2−1][ -1/2η_2^-1η_1; -1/2η_2^-1 ] (2π)−k2(2π)^-k/2 [xxxT][ 𝐱; 𝐱𝐱^𝖳 ] −14η1Tη2−1η1−12log⁡|−2η2|-1/4η_1^𝖳η_2^-1η_1-1/2log|-2η_2| 12μTΣ−1μ+12log⁡|Σ|1/2μ^𝖳Σ^-1μ+1/2log|Σ| categorical distribution(variant 1) p1,…,pk_1, ldots, p_kwhere ∑i=1kpi=1∑_i=1^kp_i=1 [log⁡p1⋮log⁡pk][ _1; ⋮; _k ] [eη1⋮eηk][ e^η_1; ⋮; e^η_k ] where ∑i=1keηi=1∑_i=1^ke^η_i=1 11 [[x=1]⋮[x=k]][ [x=1]; ⋮; [x=k] ] [x=i][x=i] is the Iverson bracket* 00 00 categorical distribution(variant 2) p1,…,pk_1, ldots, p_kwhere ∑i=1kpi=1∑_i=1^kp_i=1 [log⁡p1+C⋮log⁡pk+C][ _1+C; ⋮; _k+C ] [1Ceη1⋮1Ceηk]=[ 1Ce^η_1; ⋮; 1Ce^η_k ]= [eη1∑i=1keηi⋮eηk∑i=1keηi][ e^η_1∑_i=1^ke^η_i; ⋮; e^η_k∑_i=1^ke^η_i ] where ∑i=1keηi=C∑_i=1^ke^η_i=C 11 [[x=1]⋮[x=k]][ [x=1]; ⋮; [x=k] ] [x=i][x=i] is the Iverson bracket* 00 00 categorical distribution(variant 3) p1,…,pk_1, ldots, p_kwhere pk=1−∑i=1k−1pi_k=1-∑_i=1^k-1p_i [log⁡p1pk⋮log⁡pk−1pk0]=[ logp_1p_k; ⋮; logp_k-1p_k; 0 ]=[log⁡p11−∑i=1k−1pi⋮log⁡pk−11−∑i=1k−1pi0][ logp_11-∑_i=1^k-1p_i; ⋮; logp_k-11-∑_i=1^k-1p_i; 0 ] This is the inverse softmax function, a generalization of the logit function. [eη1∑i=1keηi⋮eηk∑i=1keηi]=[ e^η_1∑_i=1^ke^η_i; ⋮; e^η_k∑_i=1^ke^η_i ]= [eη11+∑i=1k−1eηi⋮eηk−11+∑i=1k−1eηi11+∑i=1k−1eηi][ e^η_11+∑_i=1^k-1e^η_i; ⋮; e^η_k-11+∑_i=1^k-1e^η_i; 11+∑_i=1^k-1e^η_i ] This is the softmax function, a generalization of the logistic function. 11 [[x=1]⋮[x=k]][ [x=1]; ⋮; [x=k] ] [x=i][x=i] is the Iverson bracket* log⁡(∑i=1keηi)=log⁡(1+∑i=1k−1eηi)log(∑_i=1^ke^η_i)=log(1+∑_i=1^k-1e^η_i) −log⁡pk=−log⁡(1−∑i=1k−1pi)-_k=-log(1-∑_i=1^k-1p_i) multinomial distribution(variant 1)with known number of trials n p1,…,pk_1, ldots, p_kwhere ∑i=1kpi=1∑_i=1^kp_i=1 [log⁡p1⋮log⁡pk][ _1; ⋮; _k ] [eη1⋮eηk][ e^η_1; ⋮; e^η_k ]where ∑i=1keηi=1∑_i=1^ke^η_i=1 n!∏i=1kxi!n!/∏_i=1^kx_i! [x1⋮xk][ x_1; ⋮; x_k ] 00 00 multinomial distribution(variant 2)with known number of trials n p1,…,pk_1, ldots, p_kwhere ∑i=1kpi=1∑_i=1^kp_i=1 [log⁡p1+C⋮log⁡pk+C][ _1+C; ⋮; _k+C ] [1Ceη1⋮1Ceηk]=[ 1Ce^η_1; ⋮; 1Ce^η_k ]= [eη1∑i=1keηi⋮eηk∑i=1keηi][ e^η_1∑_i=1^ke^η_i; ⋮; e^η_k∑_i=1^ke^η_i ] where ∑i=1keηi=C∑_i=1^ke^η_i=C n!∏i=1kxi!n!/∏_i=1^kx_i! [x1⋮xk][ x_1; ⋮; x_k ] 00 00 multinomial distribution(variant 3)with known number of trials n p1,…,pk_1, ldots, p_kwhere pk=1−∑i=1k−1pi_k=1-∑_i=1^k-1p_i [log⁡p1pk⋮log⁡pk−1pk0]=[ logp_1p_k; ⋮; logp_k-1p_k; 0 ]=[log⁡p11−∑i=1k−1pi⋮log⁡pk−11−∑i=1k−1pi0][ logp_11-∑_i=1^k-1p_i; ⋮; logp_k-11-∑_i=1^k-1p_i; 0 ] [eη1∑i=1keηi⋮eηk∑i=1keηi]=[ e^η_1∑_i=1^ke^η_i; ⋮; e^η_k∑_i=1^ke^η_i ]= [eη11+∑i=1k−1eηi⋮eηk−11+∑i=1k−1eηi11+∑i=1k−1eηi][ e^η_11+∑_i=1^k-1e^η_i; ⋮; e^η_k-11+∑_i=1^k-1e^η_i; 11+∑_i=1^k-1e^η_i ] n!∏i=1kxi!n!/∏_i=1^kx_i! [x1⋮xk][ x_1; ⋮; x_k ] nlog⁡(∑i=1keηi)=nlog⁡(1+∑i=1k−1eηi)log(∑_i=1^ke^η_i)=nlog(1+∑_i=1^k-1e^η_i) −nlog⁡pk=−nlog⁡(1−∑i=1k−1pi)-n_k=-nlog(1-∑_i=1^k-1p_i) Dirichlet distribution(variant 1) α1,…,αkα_1, ldots, α_k [α1⋮αk][ α_1; ⋮; α_k ] [η1⋮ηk][ η_1; ⋮; η_k ] 1∏i=1kxi1/∏_i=1^kx_i [log⁡x1⋮log⁡xk][ _1; ⋮; _k ] ∑i=1klog⁡Γ(ηi)−log⁡Γ(∑i=1kηi)∑_i=1^klogΓ(η_i)-logΓ(∑_i=1^kη_i) ∑i=1klog⁡Γ(αi)−log⁡Γ(∑i=1kαi)∑_i=1^klogΓ(α_i)-logΓ(∑_i=1^kα_i) Dirichlet distribution(variant 2) α1,…,αkα_1, ldots, α_k [α1−1⋮αk−1][ α_1-1; ⋮; α_k-1 ] [η1+1⋮ηk+1][ η_1+1; ⋮; η_k+1 ] 11 [log⁡x1⋮log⁡xk][ _1; ⋮; _k ] ∑i=1klog⁡Γ(ηi+1)−log⁡Γ(∑i=1k(ηi+1))∑_i=1^klogΓ(η_i+1)-logΓ(∑_i=1^k(η_i+1)) ∑i=1klog⁡Γ(αi)−log⁡Γ(∑i=1kαi)∑_i=1^klogΓ(α_i)-logΓ(∑_i=1^kα_i) Wishart distribution V,n𝐕, [−12V−1n−p−12][ -1/2𝐕^-1; n-p-12 ] [−12η1−12η2+p+1][ -1/2η_1^-1; 2η_2+p+1 ] 11 [Xlog⁡|X|][ 𝐗; log|𝐗| ] −(η2+p+12)log⁡|−η1|-(η_2+p+1/2)log|-η_1| +log⁡Γp(η2+p+12)=+logΓ_p(η_2+p+1/2)= −n2log⁡|−η1|+log⁡Γp(n2)=-n/2log|-η_1|+logΓ_p(n/2)= (η2+p+12)(plog⁡2+log⁡|V|)(η_2+p+1/2)(plog2+log|𝐕|) +log⁡Γp(η2+p+12)+logΓ_p(η_2+p+1/2) Three variants with different parameterizations are given, to facilitate computing moments of the sufficient statistics. n2(plog⁡2+log⁡|V|)+log⁡Γp(n2)n/2(plog2+log|𝐕|)+logΓ_p(n/2) Note: Uses the fact that tr(ATB)=vec⁡(A)⋅vec⁡(B),tr(𝐀^𝖳𝐁)=vec(𝐀)·vec(𝐁), i.e. the trace of a matrix product is much like a dot product. The matrix parameters are assumed to be vectorized (laid out in a vector) when inserted into the exponential form. Also, V𝐕 and X𝐗 are symmetric, so e.g. VT=V.𝐕^𝖳=𝐕 inverse Wishart distribution Ψ,mΨ, m [−12Ψ−m+p+12][ -1/2Ψ; -m+p+12 ] [−2η1−(2η2+p+1)][ -2η_1; -(2η_2+p+1) ] 11 [X−1log⁡|X|][ 𝐗^-1; log|𝐗| ] (η2+p+12)log⁡|−η1|(η_2+p+1/2)log|-η_1| +log⁡Γp(−(η2+p+12))=+logΓ_p(-(η_2+p+1/2))= −m2log⁡|−η1|+log⁡Γp(m2)=-m/2log|-η_1|+logΓ_p(m/2)= −(η2+p+12)(plog⁡2−log⁡|Ψ|)-(η_2+p+1/2)(plog2-log|Ψ|) +log⁡Γp(−(η2+p+12))+logΓ_p(-(η_2+p+1/2)) m2(plog⁡2−log⁡|Ψ|)+log⁡Γp(m2)m/2(plog2-log|Ψ|)+logΓ_p(m/2) normal-gamma distribution α,β,μ,λα, beta, mu, lambda [α−12−β−λμ22λμ−λ2][ α-1/2; -β-λμ^22; λμ; -λ2 ] [η1+12−η2+η324η4−η32η4−2η4][ η_1+1/2; -η_2+η_3^24η_4; -η_32η_4; -2η_4 ] 12π1√(2π) [log⁡τττxτx2][ logτ; τ; ; ^2 ] log⁡Γ(η1+12)−12log⁡(−2η4)logΓ(η_1+1/2)-1/2log(-2η_4) −(η1+12)log⁡(−η2+η324η4)-(η_1+1/2)log(-η_2+η_3^24η_4) log⁡Γ(α)−αlog⁡β−12log⁡λlogΓ(α)-αlogβ-1/2logλ * The Iverson bracket is a generalization of the discrete delta-function: If the bracketed expression is true, the bracket has value 1; if the enclosed statement is false, the Iverson bracket is zero. There are many variant notations, e.g. wavey brackets: ⧙a=b⧘ is equivalent to the [a=b] notation used above. The three variants of the categorical distribution and multinomial distribution are due to the fact that the parameters pi_i are constrained, such that ∑i=1kpi=1.∑_i=1^kp_i=1 . Thus, there are only k−1-1 independent parameters. Variant 1 uses k natural parameters with a simple relation between the standard and natural parameters; however, only k−1-1 of the natural parameters are independent, and the set of k natural parameters is nonidentifiable. The constraint on the usual parameters translates to a similar constraint on the natural parameters. Variant 2 demonstrates the fact that the entire set of natural parameters is nonidentifiable: Adding any constant value to the natural parameters has no effect on the resulting distribution. However, by using the constraint on the natural parameters, the formula for the normal parameters in terms of the natural parameters can be written in a way that is independent on the constant that is added. Variant 3 shows how to make the parameters identifiable in a convenient way by setting C=−log⁡pk.=-_k This effectively "pivots" around pk_k and causes the last natural parameter to have the constant value of 0. All the remaining formulas are written in a way that does not access pk_k}, so that effectively the model has only k−1-1 parameters, both of the usual and natural kind. Variants 1 and 2 are not actually standard exponential families at all. Rather they are curved exponential families, i.e. there are k−1-1 independent parameters embedded in a k-dimensional parameter space.[13] Many of the standard results for exponential families do not apply to curved exponential families. An example is the log-partition function A(x)(x)}, which has the value of 0 in the curved cases. In standard exponential families, the derivatives of this function correspond to the moments (more technically, the cumulants) of the sufficient statistics, e.g. the mean and variance. However, a value of 0 suggests that the mean and variance of all the sufficient statistics are uniformly 0, whereas in fact the mean of the ith sufficient statistic should be pi_i}. (This does emerge correctly when using the form of A(x)(x)} shown in variant 3.) Moments and cumulants of the sufficient