limit: The central limit theorem gives only an asymptotic distribution. As an approximation for a finite number of observations, it provides a reasonable approximation only when close to the peak of the normal distribution; it requires a very large number of observations to stretch into the tails.[citation needed] The convergence in the central limit theorem is uniform because the limiting cumulative distribution function is continuous. If the third central moment E⁡[(X1−μ)3]E[(X_1-μ)^3] exists and is finite, then the speed of convergence is at least on the order of 1/n1/√(n) (see Berry–Esseen theorem). Stein's method[19] can be used not only to prove the central limit theorem, but also to provide bounds on the rates of convergence for selected metrics.[20] The convergence to the normal distribution is monotonic, in the sense that the entropy of Zn_n increases monotonically to that of the normal distribution.[21] The central limit theorem applies in particular to sums of independent and identically distributed discrete random variables. A sum of discrete random variables is still a discrete random variable, so that we are confronted with a sequence of discrete random variables whose cumulative probability distribution function converges towards a cumulative probability distribution function corresponding to a continuous variable (namely that of the normal distribution). This means that if we build a histogram of the realizations of the sum of n independent identical discrete variables, the piecewise-linear curve that joins the centers of the upper faces of the rectangles forming the histogram converges toward a Gaussian curve as n approaches infinity; this relation is known as de Moivre–Laplace theorem. The binomial distribution article details such an application of the central limit theorem in the simple case of a discrete variable taking only two possible values. Common