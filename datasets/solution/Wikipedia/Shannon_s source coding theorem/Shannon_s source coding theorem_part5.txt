theorem: Given X is an i.i.d. source, its time series X1, ..., Xn is i.i.d. with entropy H(X) in the discrete-valued case and differential entropy in the continuous-valued case. The Source coding theorem states that for any ε > 0, i.e. for any rate H(X) + ε larger than the entropy of the source, there is large enough n and an encoder that takes n i.i.d. repetition of the source, X1:n, and maps it to n(H(X) + ε) binary bits such that the source symbols X1:n are recoverable from the binary bits with probability of at least 1 − ε. Proof of Achievability. Fix some ε > 0, and let p(x1,…,xn)=Pr[X1=x1,⋯,Xn=xn].(x_1,…,x_n)=[X_1=x_1,⋯,X_n=x_n]. The typical set, Aεn, is defined as follows: Anε=(x1,⋯,xn):|−1nlog⁡p(x1,⋯,xn)−Hn(X)|<ε._n^ε={(x_1,⋯,x_n) left|-1/n(x_1,⋯,x_n)-H_n(X)|<ε}. The asymptotic equipartition property (AEP) shows that for large enough n, the probability that a sequence generated by the source lies in the typical set, Aεn, as defined approaches one. In particular, for sufficiently large n, P((X1,X2,⋯,Xn)∈Anε)((X_1,X_2,⋯,X_n)_n^ε) can be made arbitrarily close to 1, and specifically, greater than 1−ε1-ε (See AEP for a proof). The definition of typical sets implies that those sequences that lie in the typical set satisfy: 2−n(H(X)+ε)≤p(x1,⋯,xn)≤2−n(H(X)−ε)2^-n(H(X)+ε)(x_1,⋯,x_n)≤2^-n(H(X)-ε) The probability of a sequence (X1,X2,⋯Xn)(X_1,X_2,_n) being drawn from Aεn is greater than 1 − ε. |Anε|≤2n(H(X)+ε)|A_n^ε|≤2^n(H(X)+ε), which follows from the left hand side (lower bound) for p(x1,x2,⋯xn)(x_1,x_2,_n). |Anε|≥(1−ε)2n(H(X)−ε)|A_n^ε|≥(1-ε)2^n(H(X)-ε), which follows from upper bound for p(x1,x2,⋯xn)(x_1,x_2,_n) and the lower bound on the total probability of the whole set Aεn. Since |Anε|≤2n(H(X)+ε),n(H(X)+ε)|A_n^ε|≤2^n(H(X)+ε),n(H(X)+ε) bits are enough to point to any string in this set. The encoding algorithm: the encoder checks if the input sequence lies within the typical set; if yes, it outputs the index of the input sequence within the typical set; if not, the encoder outputs an arbitrary n(H(X) + ε) digit number. As long as the input sequence lies within the typical set (with probability at least 1 − ε), the encoder does not make any error. So, the probability of error of the encoder is bounded above by ε. Proof of converse: the converse is proved by showing that any set of size smaller than Aεn (in the sense of exponent) would cover a set of probability bounded away from 1. Proof: Source coding theorem for symbol