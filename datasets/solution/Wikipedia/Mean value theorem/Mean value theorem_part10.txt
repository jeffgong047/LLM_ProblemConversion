functions: There is no exact analog of the mean value theorem for vector-valued functions (see below). However, there is an inequality which can be applied to many of the same situations to which the mean value theorem is applicable in the one dimensional case:[9] Theorem — For a continuous vector-valued function f:[a,b]→Rk𝐟:[a,b]→ℝ^k differentiable on (a,b)(a,b), there exists a number c∈(a,b)∈(a,b) such that |f(b)−f(a)|≤(b−a)|f′(c)||𝐟(b)-𝐟(a)|≤(b-a)|𝐟'(c)|. The theorem follows from the mean value theorem. Indeed, take φ(t)=(f(b)−f(a))⋅f(t)φ(t)=(f(b)-f(a))·f(t). Then φφ is real-valued and thus, by the mean value theorem, φ(b)−φ(a)=φ′(c)(b−a)φ(b)-φ(a)=φ'(c)(b-a) for some c∈(a,b)∈(a,b). Now, φ(b)−φ(a)=|f(b)−f(a)|2φ(b)-φ(a)=|f(b)-f(a)|^2 and φ′(c)=(f(b)−f(a))⋅f′(c).φ'(c)=(f(b)-f(a))·f'(c). Hence, using the Cauchy–Schwarz inequality, from the above equation, we get: |f(b)−f(a)|2≤|f(b)−f(a)||f′(c)|(b−a).|f(b)-f(a)|^2≤|f(b)-f(a)||f'(c)|(b-a). If f(b)=f(a)f(b)=f(a), the theorem is trivial (any c works). Otherwise, dividing both sides by |f(b)−f(a)||f(b)-f(a)| yields the theorem. ◻□ Jean Dieudonné in his classic treatise Foundations of Modern Analysis discards the mean value theorem and replaces it by mean inequality (which is given below) as the proof is not constructive and one cannot find the mean value and in applications one only needs mean inequality. Serge Lang in Analysis I uses the mean value theorem, in integral form, as an instant reflex but this use requires the continuity of the derivative. If one uses the Henstock–Kurzweil integral one can have the mean value theorem in integral form without the additional assumption that derivative should be continuous as every derivative is Henstock–Kurzweil integrable. The reason why there is no analog of mean value equality is the following: If f : U → Rm is a differentiable function (where U ⊂ Rn is open) and if x + th, x, h ∈ Rn, t ∈ [0, 1] is the line segment in question (lying inside U), then one can apply the above parametrization procedure to each of the component functions fi (i = 1, …, m) of f (in the above notation set y = x + h). In doing so one finds points x + tih on the line segment satisfying fi(x+h)−fi(x)=∇fi(x+tih)⋅h._i(x+h)-f_i(x)=_i(x+t_ih). But generally there will not be a single point x + t*h on the line segment satisfying fi(x+h)−fi(x)=∇fi(x+t∗h)⋅h._i(x+h)-f_i(x)=_i(x+t^*h). for all i simultaneously. For example, define: f:[0,2π]→R2f(x)=(cos⁡(x),sin⁡(x))f:[0,2π]→ℝ^2 f(x)=(cos(x),sin(x)) Then f(2π)−f(0)=0∈R2(2π)-f(0)=0∈ℝ^2, but f1′(x)=−sin⁡(x)_1'(x)=-sin(x) and f2′(x)=cos⁡(x)_2'(x)=cos(x) are never simultaneously zero as x ranges over [0,2π][0,2π]. The above theorem implies the following: Mean value inequality — [10] For a continuous function f:[a,b]→Rkf:[a,b]→ℝ^k, if ff is differentiable on (a,b)(a,b), then |f(b)−f(a)|≤(b−a)sup(a,b)|f′||f(b)-f(a)|≤(b-a)sup_(a,b)|f'|. In fact, the above statement suffices for many applications and can be proved directly as follows. (We shall write f for ff for readability.) First assume f is differentiable at a too. If f′' is unbounded on (a,b)(a,b), there is nothing to prove. Thus, assume sup(a,b)|f′|<∞sup_(a,b)|f'|<∞. Let M>sup(a,b)|f′|>sup_(a,b)|f'| be some real number. Let E=0≤t≤1∣|f(a+t(b−a))−f(a)|≤Mt(b−a).={0≤1||f(a+t(b-a))-f(a)|(b-a)}. We want to show 1∈E1. By continuity of f, the set E is closed. It is also nonempty as 00 is in it. Hence, the set E has the largest element s. If s=1=1, then 1∈E1 and we are done. Thus suppose otherwise. For 1>t>s1>t>s, |f(a+t(b−a))−f(a)|≤|f(a+t(b−a))−f(a+s(b−a))−f′(a+s(b−a))(t−s)(b−a)|+|f′(a+s(b−a))|(t−s)(b−a)+|f(a+s(b−a))−f(a)|. |f(a+t(b-a))-f(a)| ≤|f(a+t(b-a))-f(a+s(b-a))-f'(a+s(b-a))(t-s)(b-a)|+|f'(a+s(b-a))|(t-s)(b-a) +|f(a+s(b-a))-f(a)|. Let ϵ>0ϵ>0 be such that M−ϵ>sup(a,b)|f′|-ϵ>sup_(a,b)|f'|. By the differentiability of f at a+s(b−a)+s(b-a) (note s may be 0), if t is sufficiently close to s, the first term is ≤ϵ(t−s)(b−a)≤ϵ(t-s)(b-a). The second term is ≤(M−ϵ)(t−s)(b−a)≤(M-ϵ)(t-s)(b-a). The third term is ≤Ms(b−a)(b-a). Hence, summing the estimates up, we get: |f(a+t(b−a))−f(a)|≤tM|b−a||f(a+t(b-a))-f(a)||b-a|, a contradiction to the maximality of s. Hence, 1=s∈M1=s and that means: |f(b)−f(a)|≤M(b−a).|f(b)-f(a)|(b-a). Since M is arbitrary, this then implies the assertion. Finally, if f is not differentiable at a, let a′∈(a,b)'∈(a,b) and apply the first case to f restricted on [a′,b][a',b], giving us: |f(b)−f(a′)|≤(b−a′)sup(a,b)|f′||f(b)-f(a')|≤(b-a')sup_(a,b)|f'| since (a′,b)⊂(a,b)(a',b)⊂(a,b). Letting a′→a' finishes the proof. ◻□ For some applications of mean value inequality to establish basic results in calculus, see also Calculus on Euclidean space#Basic notions. A certain type of generalization of the mean value theorem to vector-valued functions is obtained as follows: Let f be a continuously differentiable real-valued function defined on an open interval I, and let x as well as x + h be points of I. The mean value theorem in one variable tells us that there exists some t* between 0 and 1 such that f(x+h)−f(x)=f′(x+t∗h)⋅h.(x+h)-f(x)=f'(x+t^*h). On the other hand, we have, by the fundamental theorem of calculus followed by a change of variables, f(x+h)−f(x)=∫xx+hf′(u)du=(∫01f′(x+th)dt)⋅h.(x+h)-f(x)=∫_x^x+hf'(u) du=(∫_0^1f'(x+th) dt). Thus, the value f′(x + t*h) at the particular point t* has been replaced by the mean value ∫01f′(x+th)dt.∫_0^1f'(x+th) dt. This last version can be generalized to vector valued functions: Proposition — Let U ⊂ Rn be open, f : U → Rm continuously differentiable, and x ∈ U, h ∈ Rn vectors such that the line segment x + th, 0 ≤ t ≤ 1 remains in U. Then we have: f(x+h)−f(x)=(∫01Df(x+th)dt)⋅h,(x+h)-f(x)=(∫_0^1Df(x+th) dt), where Df denotes the Jacobian matrix of f and the integral of a matrix is to be understood componentwise. Proof. Let f1, …, fm denote the components of f and define: gi:[0,1]→Rgi(t)=fi(x+th)g_i:[0,1]→ℝ g_i(t)=f_i(x+th) Then we have fi(x+h)−fi(x)=gi(1)−gi(0)=∫01gi′(t)dt=∫01(∑j=1n∂fi∂xj(x+th)hj)dt=∑j=1n(∫01∂fi∂xj(x+th)dt)hj.f_i(x+h)-f_i(x) =g_i(1)-g_i(0)=∫_0^1g_i'(t) dt =∫_0^1(∑_j=1^n_i/_j(x+th)h_j)dt=∑_j=1^n(∫_0^1_i/_j(x+th) dt)h_j. The claim follows since Df is the matrix consisting of the components ∂fi∂xj_i_j. ◻□ The mean value inequality can then be obtained as a corollary of the above proposition (though under the assumption the derivatives are continuous).[11] Cases where the theorem cannot be