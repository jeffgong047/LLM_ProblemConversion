Result in probability theory
In probability theory, Lévy’s continuity theorem, or Lévy's convergence theorem,[1] named after the French mathematician Paul Lévy, connects convergence in distribution of the sequence of random variables with pointwise convergence of their characteristic functions. 
This theorem is the basis for one approach to prove the central limit theorem and is one of the major theorems concerning characteristic functions.

Statement[edit]
Suppose we have

a sequence of random variables Xnn=1∞{X_n}_n=1^∞, not necessarily sharing a common probability space,the sequence of corresponding characteristic functions φnn=1∞{φ_n}_n=1^∞, which by definition are 
φn(t)=E⁡[eitXn]∀t∈R,∀n∈N,φ_n(t)=E[e^itX_n]  ∈ℝ,
foralln∈ℕ,
where EE is the expected value operator.
If the sequence of characteristic functions converges pointwise to some function φφ

φn(t)→φ(t)∀t∈R,φ_n(t)→φ(t)  ∈ℝ,
then the following statements become equivalent:

Xn_n converges in distribution to some random variable X
Xn→DX,_n{,
i.e. the cumulative distribution functions corresponding to random variables converge at every continuity point of the c.d.f. of X;Xnn=1∞{X_n}_n=1^∞ is tight: 
limx→∞(supnP⁡[|Xn|>x])=0;lim_x→∞(sup_nP[ |X_n|>x ])=0;φ(t)φ(t) is a characteristic function of some random variable X;φ(t)φ(t) is a continuous function of t;φ(t)φ(t) is continuous at t = 0.
Proof[edit]
Rigorous proofs of this theorem are available.[1][2]

References[edit]


^ a b Williams, D. (1991). Probability with Martingales. Cambridge University Press. section 18.1. ISBN 0-521-40605-6.

^ Fristedt, B. E.; Gray, L. F. (1996). A modern approach to probability theory. Boston: Birkhäuser. Theorems 14.15 and 18.21. ISBN 0-8176-3807-5.





