Convergence in distribution of binomial to normal distribution Within a system whose bins are filled according to the binomial distribution (such as Galton's "bean machine", shown here), given a sufficient number of trials (here the rows of pins, each of which causes a dropped "bean" to fall toward the left or right), a shape representing the probability distribution of k successes in n trials (see bottom of Fig. 7) matches approximately the Gaussian distribution with mean np and variance np(1−p), assuming the trials are independent and successes occur with probability p. Consider tossing a set of n coins a very large number of times and counting the number of "heads" that result each time. The possible number of heads on each toss, k, runs from 0 to n along the horizontal axis, while the vertical axis represents the relative frequency of occurrence of the outcome k heads. The height of each dot is thus the probability of observing k heads when tossing n coins (a binomial distribution based on n trials). According to the de Moivre–Laplace theorem, as n grows large, the shape of the discrete distribution converges to the continuous Gaussian curve of the normal distribution. In probability theory, the de Moivre–Laplace theorem, which is a special case of the central limit theorem, states that the normal distribution may be used as an approximation to the binomial distribution under certain conditions. In particular, the theorem shows that the probability mass function of the random number of "successes" observed in a series of n independent Bernoulli trials, each having probability p of success (a binomial distribution with n trials), converges to the probability density function of the normal distribution with mean np and standard deviation np(1−p)√(np(1-p)), as n grows large, assuming p is not 00 or 11. The theorem appeared in the second edition of The Doctrine of Chances by Abraham de Moivre, published in 1738. Although de Moivre did not use the term "Bernoulli trials", he wrote about the probability distribution of the number of times "heads" appears when a coin is tossed 3600 times.[1] This is one derivation of the particular Gaussian function used in the normal distribution. It is a special case of the central limit theorem because a Bernoulli process can be thought of as the drawing of independent random variables from a bimodal discrete distribution with non-zero probability only for values 0 and 1. In this case, the binomial distribution models the number of successes (i.e., the number of 1s), whereas the central limit theorem states that, given sufficiently large n, the distribution of the sample means will be approximately normal. However, because in this case the fraction of successes (i.e., the number of 1s divided by the number of trials, n) is equal to the sample mean, the distribution of the fractions of successes (described by the binomial distribution divided by the constant n) and the distribution of the sample means (approximately normal with large n due to the central limit theorem) are equivalent.