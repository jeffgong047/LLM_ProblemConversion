discount: Assume that the payoff of player i in a game that is repeated T times is given by a simple arithmetic mean: Ui=1T∑t=0Tui(xt)_i=1/T∑_t=0^Tu_i(x_t) A folk theorem for this case has the following additional requirement:[4] In the basic game, for every player i, there is a Nash-equilibrium Ei_i that is strictly better, for i, than his minmax payoff. This requirement is stronger than the requirement for discounted infinite games, which is in turn stronger than the requirement for undiscounted infinite games. This requirement is needed because of the last step. In the last step, the only stable outcome is a Nash-equilibrium in the basic game. Suppose a player i gains nothing from the Nash equilibrium (since it gives him only his minmax payoff). Then, there is no way to punish that player. On the other hand, if for every player there is a basic equilibrium which is strictly better than minmax, a repeated-game equilibrium can be constructed in two phases: In the first phase, the players alternate strategies in the required frequencies to approximate the desired payoff profile. In the last phase, the players play the preferred equilibrium of each of the players in turn. In the last phase, no player deviates since the actions are already a basic-game equilibrium. If an agent deviates in the first phase, he can be punished by minmaxing him in the last phase. If the game is sufficiently long, the effect of the last phase is negligible, so the equilibrium payoff approaches the desired profile.