In mathematicsÂ â€“ specifically, in the theory of stochastic processesÂ â€“ Doob's martingale convergence theorems are a collection of results on the limits of supermartingales, named after the American mathematician Joseph L. Doob.[1] Informally, the martingale convergence theorem typically refers to the result that any supermartingale satisfying a certain boundedness condition must converge. One may think of supermartingales as the random variable analogues of non-increasing sequences; from this perspective, the martingale convergence theorem is a random variable analogue of the monotone convergence theorem, which states that any bounded monotone sequence converges. There are symmetric results for submartingales, which are analogous to non-decreasing sequences.


Statement for discrete-time martingales[edit]
A common formulation of the martingale convergence theorem for discrete-time martingales is the following. Let X1,X2,X3,â€¦_1,X_2,X_3,â€¦ be a supermartingale. Suppose that the supermartingale is bounded in the sense that

suptâˆˆNEâ¡[Xtâˆ’]<âˆsup_tâˆˆğE[X_t^-]<âˆ
where Xtâˆ’_t^- is the negative part of Xt_t, defined by Xtâˆ’=âˆ’min(Xt,0)_t^-=-min(X_t,0). Then the sequence converges almost surely to a random variable X with finite expectation.
There is a symmetric statement for submartingales with bounded expectation of the positive part. A supermartingale is a stochastic analogue of a non-increasing sequence, and the condition of the theorem is analogous to the condition in the monotone convergence theorem that the sequence be bounded from below. The condition that the martingale is bounded is essential; for example, an unbiased Â±1Â±1 random walk is a martingale but does not converge.
As intuition, there are two reasons why a sequence may fail to converge. It may go off to infinity, or it may oscillate. The boundedness condition prevents the former from happening. The latter is impossible by a "gambling" argument. Specifically, consider a stock market game in which at time t, the stock has price Xt_t. There is no strategy for buying and selling the stock over time, always holding a non-negative amount of stock, which has positive expected profit in this game. The reason is that at each time the expected change in stock price, given all past information, is at most zero (by definition of a supermartingale). But if the prices were to oscillate without converging, then there would be a strategy with positive expected profit: loosely, buy low and sell high. This argument can be made rigorous to prove the result.

Proof sketch[edit]
The proof is simplified by making the (stronger) assumption that the supermartingale is uniformly bounded; that is, there is a constant M such that |Xn|â‰¤M|X_n| always holds. In the event that the sequence X1,X2,â€¦_1,X_2,â€¦ does not converge, then liminfXn_n and limsupXn_n differ. If also the sequence is bounded, then there are some real numbers a and b such that a<b<b and the sequence crosses the interval [a,b][a,b] infinitely often. That is, the sequence is eventually less than a, and at a later time exceeds b, and at an even later time is less than a, and so forth ad infinitum. These periods where the sequence starts below a and later exceeds b are called "upcrossings".
Consider a stock market game in which at time t, one may buy or sell shares of the stock at price Xt_t. On the one hand, it can be shown from the definition of a supermartingale that for any NâˆˆNâˆˆğ there is no strategy which maintains a non-negative amount of stock and has positive expected profit after playing this game for N steps. On the other hand, if the prices cross a fixed interval [a,b][a,b] very often, then the following strategy seems to do well: buy the stock when the price drops below a, and sell it when the price exceeds b. Indeed, if uN_N is the number of upcrossings in the sequence by time N, then the profit at time N is at least (bâˆ’a)uNâˆ’2M(b-a)u_N-2M: each upcrossing provides at least bâˆ’a-a profit, and if the last action was a "buy", then in the worst case the buying price was aâ‰¤M and the current price is âˆ’M-M. But any strategy has expected profit at most 00, so necessarily

Eâ¡[uN]â‰¤2Mbâˆ’a.E[u_N]â‰¤2M/b-a.
By the monotone convergence theorem for expectations, this means that 

Eâ¡[limNâ†’âˆuN]â‰¤2Mbâˆ’a,E[lim_Nâ†’âˆu_N]â‰¤2M/b-a,
so the expected number of upcrossings in the whole sequence is finite. It follows that the infinite-crossing event for interval [a,b][a,b] occurs with probability 00. By a union bound over all rational a and b, with probability 11, no interval exists which is crossed infinitely often. If for all a,bâˆˆQ,bâˆˆğ there are finitely many upcrossings of interval [a,b][a,b], then the limit inferior and limit superior of the sequence must agree, so the sequence must converge. This shows that the martingale converges with probability 11.

Failure of convergence in mean[edit]
Under the conditions of the martingale convergence theorem given above, it is not necessarily true that the supermartingale (Xn)nâˆˆN(X_n)_nâˆˆğ converges in mean (i.e. that limnâ†’âˆEâ¡[|Xnâˆ’X|]=0lim_nâ†’âˆE[|X_n-X|]=0). 
As an example,[2] let (Xn)nâˆˆN(X_n)_nâˆˆğ be a Â±1Â±1 random walk with X0=1_0=1. Let N be the first time when Xn=0_n=0, and let (Yn)nâˆˆN(Y_n)_nâˆˆğ be the stochastic process defined by Yn:=Xmin(N,n)_n:=X_min(N,n). Then N is a stopping time with respect to the martingale (Xn)nâˆˆN(X_n)_nâˆˆğ, so (Yn)nâˆˆN(Y_n)_nâˆˆğ is also a martingale, referred to as a stopped martingale. In particular, (Yn)nâˆˆN(Y_n)_nâˆˆğ is a supermartingale which is bounded below, so by the martingale convergence theorem it converges pointwise almost surely to a random variable Y. But if Yn>0_n>0 then Yn+1=YnÂ±1_n+1=Y_nÂ±1, so Y is almost surely zero.
This means that Eâ¡[Y]=0E[Y]=0. However, Eâ¡[Yn]=1E[Y_n]=1 for every nâ‰¥1â‰¥1, since (Yn)nâˆˆN(Y_n)_nâˆˆğ is a random walk which starts at 11 and subsequently makes mean-zero moves  (alternately, note that Eâ¡[Yn]=Eâ¡[Y0]=1E[Y_n]=E[Y_0]=1 since (Yn)nâˆˆN(Y_n)_nâˆˆğ is a martingale). Therefore (Yn)nâˆˆN(Y_n)_nâˆˆğ cannot converge to Y in mean. Moreover, if (Yn)nâˆˆN(Y_n)_nâˆˆâ„• were to converge in mean to any random variable R, then some subsequence converges to R almost surely. So by the above argument R=0=0 almost surely, which contradicts convergence in mean.

Statements for the general case[edit]
In the following, (Î©,F,Fâˆ—,P)(Î©,F,F_*,ğ) will be a filtered probability space where Fâˆ—=(Ft)tâ‰¥0_*=(F_t)_tâ‰¥0, and N:[0,âˆ)Ã—Î©â†’R:[0,âˆ)Ã—Î©â†’ğ‘ will be a right-continuous supermartingale with respect to the filtration Fâˆ—_*;  in other words, for all 0â‰¤sâ‰¤t<+âˆ0<+âˆ,

Nsâ‰¥Eâ¡[Ntâˆ£Fs]._sâ‰¥E[N_t_s].
Doob's first martingale convergence theorem[edit]
Doob's first martingale convergence theorem provides a sufficient condition for the random variables Nt_t to have a limit as tâ†’+âˆâ†’+âˆ in a pointwise sense, i.e. for each Ï‰Ï‰ in the sample space Î©Î© individually.
For tâ‰¥0â‰¥0, let Ntâˆ’=max(âˆ’Nt,0)_t^-=max(-N_t,0) and suppose that

supt>0Eâ¡[Ntâˆ’]<+âˆ.sup_t>0E[N_t^-]<+âˆ.
Then the pointwise limit

N(Ï‰)=limtâ†’+âˆNt(Ï‰)(Ï‰)=lim_tâ†’+âˆN_t(Ï‰)
exists and is finite for Pğ-almost all Ï‰âˆˆÎ©Ï‰âˆˆÎ©.[3]

Doob's second martingale convergence theorem[edit]
It is important to note that the convergence in Doob's first martingale convergence theorem is pointwise, not uniform, and is unrelated to convergence in mean square, or indeed in any Lp space. In order to obtain convergence in L1 (i.e., convergence in mean), one requires uniform integrability of the random variables Nt_t. By Chebyshev's inequality, convergence in L1 implies convergence in probability and convergence in distribution.
The following are equivalent:

(Nt)t>0(N_t)_t>0 is uniformly integrable, i.e.
limCâ†’âˆsupt>0âˆ«Ï‰âˆˆÎ©âˆ£|Nt(Ï‰)|>C|Nt(Ï‰)|dP(Ï‰)=0;lim_Câ†’âˆsup_t>0âˆ«_{Ï‰âˆˆÎ© | |N_t(Ï‰)|>C}|N_t(Ï‰)| dğ(Ï‰)=0;
there exists an integrable random variable NâˆˆL1(Î©,P;R)^1(Î©,ğ;ğ‘) such that Ntâ†’N_t as tâ†’âˆâ†’âˆ both Pğ-almost surely and in L1(Î©,P;R)^1(Î©,ğ;ğ‘), i.e.
Eâ¡[|Ntâˆ’N|]=âˆ«Î©|Nt(Ï‰)âˆ’N(Ï‰)|dP(Ï‰)â†’0astâ†’+âˆ.E[|N_t-N|]=âˆ«_Î©|N_t(Ï‰)-N(Ï‰)| dğ(Ï‰)â†’0astâ†’+âˆ.
Doob's upcrossing inequality[edit]
The following result, called Doob's upcrossing inequality or, sometimes, Doob's upcrossing lemma, is used in proving Doob's martingale convergence theorems.[3] A "gambling" argument shows that for uniformly bounded supermartingales, the number of upcrossings is bounded; the upcrossing lemma generalizes this argument to supermartingales with bounded expectation of their negative parts.
Let N be a natural number. Let (Xn)nâˆˆN(X_n)_nâˆˆğ be a supermartingale with respect to a filtration (Fn)nâˆˆN(â„±_n)_nâˆˆğ. Let a, b be two real numbers with a<b<b. Define the random variables (Un)nâˆˆN(U_n)_nâˆˆğ so that Un_n is the maximum number of disjoint intervals [ni1,ni2][n_i_1,n_i_2] with ni2â‰¤n_i_2, such that Xni1<a<b<Xni2_n_i_1<a<b<X_n_i_2. These are called upcrossings with respect to interval [a,b][a,b]. Then

(bâˆ’a)Eâ¡[Un]â‰¤Eâ¡[(Xnâˆ’a)âˆ’].(b-a)E[U_n]â‰¤E[(X_n-a)^-].  
where Xâˆ’^- is the negative part of X, defined by Xâˆ’=âˆ’min(X,0)^-=-min(X,0).[4][5]

Applications[edit]
Convergence in Lp[edit]
Let M:[0,âˆ)Ã—Î©â†’R:[0,âˆ)Ã—Î©â†’ğ‘ be a continuous martingale such that

supt>0Eâ¡[|Mt|p]<+âˆsup_t>0E[|M_t|^p]<+âˆ
for some p>1>1. Then there exists a random variable MâˆˆLp(Î©,P;R)^p(Î©,ğ;ğ‘) such that Mtâ†’M_t as tâ†’+âˆâ†’+âˆ both Pğ-almost surely and in Lp(Î©,P;R)^p(Î©,ğ;ğ‘).
The statement for discrete-time martingales is essentially identical, with the obvious difference that the continuity assumption is no longer necessary.

 LÃ©vy's zeroâ€“one law[edit]
Doob's martingale convergence theorems imply that conditional expectations also have a convergence property.
Let (Î©,F,P)(Î©,F,ğ) be a probability space and let X be a random variable in L1^1. Let Fâˆ—=(Fk)kâˆˆN_*=(F_k)_kâˆˆğ be any filtration of F, and define Fâˆ_âˆ to be the minimal Ïƒ-algebra generated by (Fk)kâˆˆN(F_k)_kâˆˆğ. Then

Eâ¡[Xâˆ£Fk]â†’Eâ¡[Xâˆ£Fâˆ]askâ†’âˆE[X_k]â†’E[X_âˆ]askâ†’âˆ
both Pğ-almost surely and in L1^1.
This result is usually called LÃ©vy's zeroâ€“one law or Levy's upwards theorem. The reason for the name is that if A is an event in Fâˆ_âˆ, then the theorem says that P[Aâˆ£Fk]â†’1Ağ[A_k]â†’1_A almost surely, i.e., the limit of the probabilities is 0 or 1. In plain language, if we are learning gradually all the information that determines the outcome of an event, then we will become gradually certain what the outcome will be. This sounds almost like a tautology, but the result is still non-trivial. For instance, it easily implies Kolmogorov's zeroâ€“one law, since it says that for any tail event A, we must have P[A]=1Ağ[A]=1_A almost surely, hence P[A]âˆˆ0,1ğ[A]âˆˆ{0,1}.
Similarly we have the Levy's downwards theoremÂ :
Let (Î©,F,P)(Î©,F,ğ) be a probability space and let X be a random variable in L1^1. Let (Fk)kâˆˆN(F_k)_kâˆˆğ be any decreasing sequence of sub-sigma algebras of F, and define Fâˆ_âˆ to be the intersection. Then

Eâ¡[Xâˆ£Fk]â†’Eâ¡[Xâˆ£Fâˆ]askâ†’âˆE[X_k]â†’E[X_âˆ]askâ†’âˆ
both Pğ-almost surely and in L1^1.

See also[edit]
Backwards martingale convergence theorem[6]
This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (January 2012) (Learn how and when to remove this template message)
References[edit]


^ Doob, J. L. (1953). Stochastic Processes. New York: Wiley.

^ Durrett, Rick (1996). Probability: theory and examples (SecondÂ ed.). Duxbury Press. ISBNÂ 978-0-534-24318-0.; Durrett, Rick (2010). 4th edition. ISBNÂ 9781139491136.

^ a b "Martingale Convergence Theorem" (PDF). Massachusetts Institute of Tecnnology, 6.265/15.070J Lecture 11-Additional Material, Advanced Stochastic Processes, Fall 2013, 10/9/2013.

^ Bobrowski, Adam (2005). Functional Analysis for Probability and Stochastic Processes: An Introduction. Cambridge University Press. pp.Â 113â€“114. ISBNÂ 9781139443883.

^ Gushchin, A. A. (2014). "On pathwise counterparts of Doob's maximal inequalities". Proceedings of the Steklov Institute of Mathematics. 287 (287): 118â€“121. arXiv:1410.8264. doi:10.1134/S0081543814080070. S2CIDÂ 119150374.

^ Doob, Joseph L. (1994). Measure theory. Graduate Texts in Mathematics, Vol. 143. Springer. p.Â 197. ISBNÂ 9781461208778.


Ã˜ksendal, Bernt K. (2003). Stochastic Differential Equations: An Introduction with Applications (SixthÂ ed.). Berlin: Springer. ISBNÂ 3-540-04758-1. (See Appendix C)



