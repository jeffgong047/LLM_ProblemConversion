integration: In statistical applications, many problems can be formulated in the following way. One is interested in the expectation of a response function g:Rd→R:ℝ^d→ℝ applied to some random vector (X1,…,Xd)(X_1,…,X_d).[18] If we denote the CDF of this random vector with H, the quantity of interest can thus be written as E⁡[g(X1,…,Xd)]=∫Rdg(x1,…,xd)dH(x1,…,xd).E[g(X_1,…,X_d)]=∫_ℝ^dg(x_1,…,x_d) dH(x_1,…,x_d). If H is given by a copula model, i.e., H(x1,…,xd)=C(F1(x1),…,Fd(xd))(x_1,…,x_d)=C(F_1(x_1),…,F_d(x_d)) this expectation can be rewritten as E⁡[g(X1,…,Xd)]=∫[0,1]dg(F1−1(u1),…,Fd−1(ud))dC(u1,…,ud).E[g(X_1,…,X_d)]=∫_[0,1]^dg(F_1^-1(u_1),…,F_d^-1(u_d)) dC(u_1,…,u_d). In case the copula C is absolutely continuous, i.e. C has a density c, this equation can be written as E⁡[g(X1,…,Xd)]=∫[0,1]dg(F1−1(u1),…,Fd−1(ud))⋅c(u1,…,ud)du1⋯dud,E[g(X_1,…,X_d)]=∫_[0,1]^dg(F_1^-1(u_1),…,F_d^-1(u_d))(u_1,…,u_d) du_1⋯du_d, and if each marginal distribution has the density fi_i it holds further that E⁡[g(X1,…,Xd)]=∫Rdg(x1,…xd)⋅c(F1(x1),…,Fd(xd))⋅f1(x1)⋯fd(xd)dx1⋯dxd.E[g(X_1,…,X_d)]=∫_ℝ^dg(x_1,_d)(F_1(x_1),…,F_d(x_d))_1(x_1)_d(x_d) dx_1⋯dx_d. If copula and marginals are known (or if they have been estimated), this expectation can be approximated through the following Monte Carlo algorithm: Draw a sample (U1k,…,Udk)∼C(k=1,…,n)(U_1^k,…,U_d^k) (k=1,…,n) of size n from the copula C By applying the inverse marginal cdf's, produce a sample of (X1,…,Xd)(X_1,…,X_d) by setting (X1k,…,Xdk)=(F1−1(U1k),…,Fd−1(Udk))∼H(k=1,…,n)(X_1^k,…,X_d^k)=(F_1^-1(U_1^k),…,F_d^-1(U_d^k)) (k=1,…,n) Approximate E⁡[g(X1,…,Xd)]E[g(X_1,…,X_d)] by its empirical value: E⁡[g(X1,…,Xd)]≈1n∑k=1ng(X1k,…,Xdk)E[g(X_1,…,X_d)]≈1/n∑_k=1^ng(X_1^k,…,X_d^k) Empirical