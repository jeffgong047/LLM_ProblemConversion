Remark: Proof that the OLS indeed minimizes the sum of squares of residuals may proceed as follows with a calculation of the Hessian matrix and showing that it is positive definite. The MSE function we want to minimize is f(Î²0,Î²1,â€¦,Î²p)=âˆ‘i=1n(yiâˆ’Î²0âˆ’Î²1xi1âˆ’â‹¯âˆ’Î²pxip)2(Î²_0,Î²_1,â€¦,Î²_p)=âˆ‘_i=1^n(y_i-Î²_0-Î²_1x_i1-â€¦-Î²_px_ip)^2 for a multiple regression model with p variables. The first derivative is ddÎ²f=âˆ’2XT(yâˆ’XÎ²)=âˆ’2[âˆ‘i=1n(yiâˆ’â‹¯âˆ’Î²pxip)âˆ‘i=1nxi1(yiâˆ’â‹¯âˆ’Î²pxip)â‹®âˆ‘i=1nxip(yiâˆ’â‹¯âˆ’Î²pxip)]=0p+1,d/dÎ²f =-2X^T(ğ²-XÎ²) =-2[ âˆ‘_i=1^n(y_i-â€¦-Î²_px_ip); âˆ‘_i=1^nx_i1(y_i-â€¦-Î²_px_ip); â‹®; âˆ‘_i=1^nx_ip(y_i-â€¦-Î²_px_ip) ] =0_p+1, where XT^T is the design matrix X=[1x11â‹¯x1p1x21â‹¯x2pâ‹®1xn1â‹¯xnp]âˆˆRnÃ—(p+1);nâ‰¥p+1=[ 1 x_11 â‹¯ x_1p; 1 x_21 â‹¯ x_2p; â‹®; 1 x_n1 â‹¯ x_np ]âˆˆâ„^nÃ—(p+1);+1 The Hessian matrix of second derivatives is H=2[nâˆ‘i=1nxi1â‹¯âˆ‘i=1nxipâˆ‘i=1nxi1âˆ‘i=1nxi12â‹¯âˆ‘i=1nxi1xipâ‹®â‹®â‹±â‹®âˆ‘i=1nxipâˆ‘i=1nxipxi1â‹¯âˆ‘i=1nxip2]=2XTXâ„‹=2[ n âˆ‘_i=1^nx_i1 â‹¯ âˆ‘_i=1^nx_ip; âˆ‘_i=1^nx_i1 âˆ‘_i=1^nx_i1^2 â‹¯ âˆ‘_i=1^nx_i1x_ip; â‹® â‹® â‹± â‹®; âˆ‘_i=1^nx_ip âˆ‘_i=1^nx_ipx_i1 â‹¯ âˆ‘_i=1^nx_ip^2 ]=2X^TX Assuming the columns of X are linearly independent so that XTX^TX is invertible, let X=[v1v2â‹¯vp+1]=[ ğ¯_1 ğ¯_2 â‹¯ ğ¯_p+1 ], then k1v1+â‹¯+kp+1vp+1=0âŸºk1=â‹¯=kp+1=0_1ğ¯_1+â€¦+k_p+1ğ¯_p+1=0_1=â€¦=k_p+1=0 Now let k=(k1,â€¦,kp+1)TâˆˆR(p+1)Ã—1ğ¤=(k_1,â€¦,k_p+1)^Tâˆˆâ„^(p+1)Ã—1 be an eigenvector of Hâ„‹. kâ‰ 0âŸ¹(k1v1+â‹¯+kp+1vp+1)2>0ğ¤â‰ 0(k_1ğ¯_1+â€¦+k_p+1ğ¯_p+1)^2>0 In terms of vector multiplication, this means [k1â‹¯kp+1][v1â‹®vp+1][v1â‹¯vp+1][k1â‹®kp+1]=kTHk=Î»kTk>0[ k_1 â‹¯ k_p+1 ][ ğ¯_1; â‹®; ğ¯_p+1 ][ ğ¯_1 â‹¯ ğ¯_p+1 ][ k_1; â‹®; k_p+1 ]=ğ¤^Tâ„‹ğ¤=Î»ğ¤^Tğ¤>0 where Î»Î» is the eigenvalue corresponding to kğ¤. Moreover, kTk=âˆ‘i=1p+1ki2>0âŸ¹Î»>0ğ¤^Tğ¤=âˆ‘_i=1^p+1k_i^2>0Î»>0 Finally, as eigenvector kğ¤ was arbitrary, it means all eigenvalues of Hâ„‹ are positive, therefore Hâ„‹ is positive definite. Thus, Î²=(XTX)âˆ’1XTYÎ²=(X^TX)^-1X^TY is indeed a global minimum. Or, just see that for all vectors v,vTXTXv=â€–Xvâ€–2â‰¥0ğ¯,ğ¯^TX^TXğ¯=ğ—ğ¯^2â‰¥0. So the Hessian is positive definite if full rank.