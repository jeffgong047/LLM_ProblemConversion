Theory of probability
The left diagram illustrates Glivenkoâ€“Cantelli theorem for uniform distributions. The right diagram illustrates the Donskerâ€“Skorokhodâ€“Kolmogorov theorem
The same diagram for normal distributions
In the theory of probability, the Glivenkoâ€“Cantelli theorem (sometimes referred to as the Fundamental Theorem of Statistics), named after Valery Ivanovich Glivenko and Francesco Paolo Cantelli,  determines the asymptotic behaviour of the empirical distribution function as the number of independent and identically distributed observations grows.[1]
The uniform convergence of  more general empirical measures becomes an important property of the Glivenkoâ€“Cantelli classes of functions or sets.[2]  The Glivenkoâ€“Cantelli classes arise in Vapnikâ€“Chervonenkis theory, with applications to machine learning. Applications can be found in econometrics making use of M-estimators.


Statement[edit]
Assume that  X1,X2,â€¦_1,X_2,â€¦ are independent and identically distributed random variables in Râ„ with common cumulative distribution function F(x)(x). The empirical distribution function for X1,â€¦,Xn_1,â€¦,X_n is defined by

Fn(x)=1nâˆ‘i=1nI[Xi,âˆ)(x)=1n|iâˆ£Xiâ‰¤x,1â‰¤iâ‰¤n|_n(x)=1nâˆ‘_i=1^nI_[X_i,âˆ)(x)=1n{|{Ä±
midX_i,}|
where IC_C is the indicator function of the set C.Â . For every (fixed) x,  Fn(x)_n(x)} is a sequence of random variables which converge to F(x)(x) almost surely by the strong law of large numbers. Glivenko and Cantelli strengthened this result by proving uniform convergence of Fn_n} to F.Â .
Theorem

â€–Fnâˆ’Fâ€–âˆ=supxâˆˆR|Fn(x)âˆ’F(x)|âŸ¶0F_n-F_âˆ=sup_xâˆˆâ„|F_n(x)-F(x)|âŸ¶0 almost surely.[3](pâ€¯265)
This theorem originates with Valery Glivenko[4] and Francesco Cantelli,[5] in 1933.

Remarks

If Xn_n} is a stationary ergodic process, then Fn(x)_n(x) converges almost surely to F(x)=Eâ¡[1X1â‰¤x].(x)=ğ”¼[1_X_1]Â . The Glivenkoâ€“Cantelli theorem gives a stronger mode of convergence than this in the iid case.
An even stronger uniform convergence result for the empirical distribution function is available in the form of an extended type of law of the iterated logarithm.[3](pâ€¯268) See asymptotic properties of the empirical distribution function for this and related results.
Proof[edit]
For simplicity, consider a case of continuous random variable X. Fix âˆ’âˆ=x0<x1<â‹¯<xmâˆ’1<xm=âˆ-âˆ=x_0<x_1<â‹¯<x_m-1<x_m=âˆ such that F(xj)âˆ’F(xjâˆ’1)=1m(x_j)-F(x_j-1)=1/m for j=1,â€¦,m=1,â€¦,m. Now for all xâˆˆRâˆˆâ„ there exists jâˆˆ1,â€¦,mâˆˆ{1,â€¦,m} such that xâˆˆ[xjâˆ’1,xj]âˆˆ[x_j-1,x_j]. Note that

Fn(x)âˆ’F(x)â‰¤Fn(xj)âˆ’F(xjâˆ’1)=Fn(xj)âˆ’F(xj)+1m,Fn(x)âˆ’F(x)â‰¥Fn(xjâˆ’1)âˆ’F(xj)=Fn(xjâˆ’1)âˆ’F(xjâˆ’1)âˆ’1m.F_n(x)-F(x)   _n(x_j)-F(x_j-1)=F_n(x_j)-F(x_j)+1/m,
F_n(x)-F(x)   _n(x_j-1)-F(x_j)=F_n(x_j-1)-F(x_j-1)-1/m.
Therefore,

â€–Fnâˆ’Fâ€–âˆ=supxâˆˆR|Fn(x)âˆ’F(x)|â‰¤maxjâˆˆ1,â€¦,m|Fn(xj)âˆ’F(xj)|+1m.F_n-F_âˆ=sup_xâˆˆâ„|F_n(x)-F(x)|â‰¤max_jâˆˆ{1,â€¦,m}|F_n(x_j)-F(x_j)|+1/m.
Since maxjâˆˆ1,â€¦,m|Fn(xj)âˆ’F(xj)|â†’0a.s.max_jâˆˆ{1,â€¦,m}|F_n(x_j)-F(x_j)|â†’0a.s. by strong law of large numbers, we can guarantee that for any positive ÎµÎµ and any integer m such that 1/m<Îµ1/m<Îµ, we can find N such that for all nâ‰¥N, we have maxjâˆˆ1,â€¦,m|Fn(xj)âˆ’F(xj)|â‰¤Îµâˆ’1/ma.s.max_jâˆˆ{1,â€¦,m}|F_n(x_j)-F(x_j)|â‰¤Îµ-1/ma.s.. Combined with the above result, this further implies that â€–Fnâˆ’Fâ€–âˆâ‰¤Îµa.s.F_n-F_âˆâ‰¤Îµa.s., which is the definition of almost sure convergence.

Empirical measures[edit]
One can generalize the empirical distribution function by replacing the set (âˆ’âˆ,x](-âˆ,x] by an arbitrary set C from a class of sets Cğ’ to obtain an empirical measure indexed by sets CâˆˆC.âˆˆğ’.

Pn(C)=1nâˆ‘i=1nIC(Xi),CâˆˆC_n(C)=1/nâˆ‘_i=1^nI_C(X_i),Câˆˆğ’
Where IC(x)_C(x) is the indicator function of each set C.
Further generalization is the map induced by Pn_n on measurable real-valued functions f, which is given by

fâ†¦Pnf=âˆ«SfdPn=1nâˆ‘i=1nf(Xi),fâˆˆF._nf=âˆ«_Sf dP_n=1/nâˆ‘_i=1^nf(X_i),fâˆˆâ„±.
Then it becomes an important property of these classes whether the strong law of large numbers holds uniformly on Fâ„± or Cğ’.

Glivenkoâ€“Cantelli class[edit]
Consider a set S{ğ’®} with a sigma algebra of Borel subsets A and a probability measure P.
mathbbPÂ . For a class of subsets,

CâŠ‚C:CismeasurablesubsetofSğ’âŠ‚{C:Cismeasurablesubsetofğ’®}
and a class of functions

FâŠ‚f:Sâ†’R,fismeasurableâ„±âŠ‚{f:ğ’®â†’â„,f{}
define random variables

â€–Pnâˆ’Pâ€–C=supCâˆˆC|Pn(C)âˆ’P(C)|P_n-P_ğ’=sup_Câˆˆğ’|â„™_n(C)-â„™(C)|
â€–Pnâˆ’Pâ€–F=supfâˆˆF|Pnfâˆ’Pf|P_n-P_â„±=sup_fâˆˆâ„±|â„™_nf-â„™f|
where Pn(C)
mathbbP_n(C)} is the empirical measure, Pnf
mathbbP_nf} is the corresponding map, and

Eâ¡f=âˆ«SfdP=Pf,
operatornameğ”¼f=âˆ«_ğ’®f
mathrmdâ„™=â„™f  assuming that it exists.
Definitions

A class C{ğ’} is called a  Glivenkoâ€“Cantelli class  (or GC class) with respect to a probability measure P if any of the following equivalent statements is true.
1. â€–Pnâˆ’Pâ€–Câ†’0{â„™_n-â„™_ğ’â†’0} almost surely as nâ†’âˆ.â†’âˆÂ .
2. â€–Pnâˆ’Pâ€–Câ†’0{â„™_n-â„™_ğ’â†’0} in probability as nâ†’âˆ.â†’âˆÂ .
3. Eâ¡â€–Pnâˆ’Pâ€–Câ†’0,
operatornameğ”¼â„™_n-â„™_ğ’â†’0  as nâ†’âˆâ†’âˆ} (convergence in mean).
The Glivenkoâ€“Cantelli classes of functions are defined similarly.
A class is called a universal Glivenkoâ€“Cantelli class if it is a GC class with respect to any probability measure Pâ„™ on (S,A)Â .
A class is called uniformly Glivenkoâ€“Cantelli if the convergence occurs uniformly over all probability measures Pâ„™ on (S,A)Â :
supPâˆˆP(S,A)Eâ¡â€–Pnâˆ’Pâ€–Câ†’0;sup_â„™âˆˆâ„™(S,A)ğ”¼â„™_n-â„™_ğ’â†’0 
supPâˆˆP(S,A)Eâ¡â€–Pnâˆ’Pâ€–Fâ†’0.sup_â„™âˆˆâ„™(S,A)ğ”¼â„™_n-â„™_â„±â†’0Â .
Theorem (Vapnik and Chervonenkis, 1968)[6]

A class of sets C{ğ’} is uniformly GC if and only if it is a Vapnikâ€“Chervonenkis class. 
Examples[edit]
Let S=R=â„ and C=(âˆ’âˆ,t]:tâˆˆRğ’={(-âˆ,t]:tâˆˆâ„}. The classical Glivenkoâ€“Cantelli theorem implies that this class is a universal GC class. Furthermore, by Kolmogorov's theorem,
supPâˆˆP(S,A)â€–Pnâˆ’Pâ€–Câˆ¼nâˆ’1/2sup_Pâˆˆğ’«(S,A)P_n-P_ğ’^-1/2, that is Cğ’ is uniformly Glivenkoâ€“Cantelli class.
Let P be a nonatomic probability measure on S and Cğ’ be a class of all finite subsets in S. Because An=X1,â€¦,XnâˆˆC_n={X_1,â€¦,X_n}âˆˆğ’, P(An)=0(A_n)=0, Pn(An)=1_n(A_n)=1, we have that â€–Pnâˆ’Pâ€–C=1P_n-P_ğ’=1 and so Cğ’ is not a GC class with respect to P.
See also[edit]
Donsker's theorem
Dvoretzkyâ€“Kieferâ€“Wolfowitz inequality â€“ strengthens the Glivenkoâ€“Cantelli theorem by quantifying the rate of convergence.
References[edit]


^ Howard G.Tucker (1959). "A Generalization of the Glivenkoâ€“Cantelli Theorem". The Annals of Mathematical Statistics. 30 (3): 828â€“830. doi:10.1214/aoms/1177706212. JSTORÂ 2237422.

^ van der Vaart, A. W. (1998). Asymptotic Statistics. Cambridge University Press. p.Â 279. ISBNÂ 978-0-521-78450-4.

^ a b van der Vaart, A.W. (1998). Asymptotic Statistics. Cambridge University Press. ISBNÂ 978-0-521-78450-4.

^ Glivenko, V. (1933). "Sulla determinazione empirica delle leggi di probabilitÃ ". Giorn. Ist. Ital. Attuari (in Italian). 4: 92â€“99.

^ Cantelli, F.P. (1933). "Sulla determinazione empirica delle leggi di probabilitÃ ". Giorn. Ist. Ital. Attuari. 4: 421â€“424.

^ Vapnik, V.N.; Chervonenkis, A.Ya. (1971). "On the Uniform Convergence of Relative Frequencies of Events to Their Probabilities". Theory of Probability & Its Applications. 16 (2): 264â€“280. doi:10.1137/1116025.


Further reading[edit]

Dudley, R.M. (1999). Uniform Central Limit Theorems. Cambridge University Press. ISBNÂ 0-521-46102-2.
Pitman, E.J.G. (1979). "The Sample Distribution Function". Some Basic Theory for Statistical Inference. London, UK: Chapman and Hall. p.Â 79â€“97. ISBNÂ 0-470-26554-X.
Shorack, G.R.; Wellner, J.A. (1986). Empirical Processes with Applications to Statistics. Wiley. ISBNÂ 0-471-86725-X.
van der Vaart, A.W.; Wellner, J.A. (1996). Weak Convergence and Empirical Processes. Springer. ISBNÂ 0-387-94640-3.
van der Vaart, Aad W.; Wellner, Jon A. (1996). Glivenko-Cantelli Theorems. Springer.
van der Vaart, Aad W.; Wellner, Jon A. (2000). Preservation Theorems for Glivenkoâ€“Cantelli and Uniform Glivenkoâ€“Cantelli Classes. Springer.




