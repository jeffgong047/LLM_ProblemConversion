variance: If X1, ..., Xn are independent normally distributed random variables with mean μ and standard deviation σ then Ui=Xi−μσ_i=X_i-μ/σ is standard normal for each i. Note that the total Q is equal to sum of squared Us as shown here: ∑iQi=∑jikUjBjk(i)Uk=∑jkUjUk∑iBjk(i)=∑jkUjUkδjk=∑jUj2∑_iQ_i=∑_jikU_jB_jk^(i)U_k=∑_jkU_jU_k∑_iB_jk^(i)=∑_jkU_jU_kδ_jk=∑_jU_j^2 which stems from the original assumption that B1+B2…=I_1+B_2…=I. So instead we will calculate this quantity and later separate it into Qi's. It is possible to write ∑i=1nUi2=∑i=1n(Xi−X¯σ)2+n(X¯−μσ)2∑_i=1^nU_i^2=∑_i=1^n(X_i-X/σ)^2+n(X-μ/σ)^2 (here X¯X is the sample mean). To see this identity, multiply throughout by σ2σ^2 and note that ∑(Xi−μ)2=∑(Xi−X¯+X¯−μ)2∑(X_i-μ)^2=∑(X_i-X+X-μ)^2 and expand to give ∑(Xi−μ)2=∑(Xi−X¯)2+∑(X¯−μ)2+2∑(Xi−X¯)(X¯−μ).∑(X_i-μ)^2=∑(X_i-X)^2+∑(X-μ)^2+2∑(X_i-X)(X-μ). The third term is zero because it is equal to a constant times ∑(X¯−Xi)=0,∑(X-X_i)=0, and the second term has just n identical terms added together. Thus ∑(Xi−μ)2=∑(Xi−X¯)2+n(X¯−μ)2,∑(X_i-μ)^2=∑(X_i-X)^2+n(X-μ)^2, and hence ∑(Xi−μσ)2=∑(Xi−X¯σ)2+n(X¯−μσ)2=∑i(Ui−1n∑jUj)2⏞Q1+1n(∑jUj)2⏞Q2=Q1+Q2.∑(X_i-μ/σ)^2=∑(X_i-X/σ)^2+n(X-μ/σ)^2=∑_i(U_i-1/n∑_jU_j)^2^Q_1+1/n(∑_jU_j)^2^Q_2=Q_1+Q_2. Now B(2)=Jnn^(2)=J_n/n with Jn_n the matrix of ones which has rank 1. In turn B(1)=In−Jnn^(1)=I_n-J_n/n given that In=B(1)+B(2)_n=B^(1)+B^(2). This expression can be also obtained by expanding Q1_1 in matrix notation. It can be shown that the rank of B(1)^(1) is n−1-1 as the addition of all its rows is equal to zero. Thus the conditions for Cochran's theorem are met. Cochran's theorem then states that Q1 and Q2 are independent, with chi-squared distributions with n − 1 and 1 degree of freedom respectively. This shows that the sample mean and sample variance are independent. This can also be shown by Basu's theorem, and in fact this property characterizes the normal distribution – for no other distribution are the sample mean and sample variance independent.[4]