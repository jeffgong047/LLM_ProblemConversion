Proof: The proof is by induction on the dimension of gğ”¤ and consists of several steps. (Note: the structure of the proof is very similar to that for Engel's theorem.) The basic case is trivial and we assume the dimension of gğ”¤ is positive. We also assume V is not zero. For simplicity, we write Xâ‹…v=Ï€(X)(v)=Ï€(X)(v). Step 1: Observe that the theorem is equivalent to the statement:[3] There exists a vector in V that is an eigenvector for each linear transformation in Ï€(g)Ï€(ğ”¤). Indeed, the theorem says in particular that a nonzero vector spanning Vnâˆ’1_n-1 is a common eigenvector for all the linear transformations in Ï€(g)Ï€(ğ”¤). Conversely, if v is a common eigenvector, take Vnâˆ’1_n-1 to its span and then Ï€(g)Ï€(ğ”¤) admits a common eigenvector in the quotient V/Vnâˆ’1/V_n-1; repeat the argument. Step 2: Find an ideal hğ”¥ of codimension one in gğ”¤. Let Dg=[g,g]ğ”¤=[ğ”¤,ğ”¤] be the derived algebra. Since gğ”¤ is solvable and has positive dimension, Dgâ‰ gğ”¤â‰ ğ”¤ and so the quotient g/Dgğ”¤/Dğ”¤ is a nonzero abelian Lie algebra, which certainly contains an ideal of codimension one and by the ideal correspondence, it corresponds to an ideal of codimension one in gğ”¤. Step 3: There exists some linear functional Î»Î» in hâˆ—ğ”¥^* such that VÎ»=vâˆˆV|Xâ‹…v=Î»(X)v,Xâˆˆh_Î»={v|X=Î»(X)v,Xâˆˆğ”¥} is nonzero. This follows from the inductive hypothesis (it is easy to check that the eigenvalues determine a linear functional). Step 4: VÎ»_Î» is a gğ”¤-invariant subspace. (Note this step proves a general fact and does not involve solvability.) Let Yâˆˆgâˆˆğ”¤, vâˆˆVÎ»_Î», then we need to prove Yâ‹…vâˆˆVÎ»_Î». If v=0=0 then it's obvious, so assume vâ‰ 0â‰ 0 and set recursively v0=v,vi+1=Yâ‹…vi_0=v, v_i+1=Y_i. Let U=spanâ¡vi|iâ‰¥0=span{v_i|iâ‰¥0} and â„“âˆˆN0â„“âˆˆâ„•_0 be the largest such that v0,â€¦,vâ„“_0,â€¦,v_â„“ are linearly independent. Then we'll prove that they generate U and thus Î±=(v0,â€¦,vâ„“)Î±=(v_0,â€¦,v_â„“) is a basis of U. Indeed, assume by contradiction that it's not the case and let mâˆˆN0âˆˆâ„•_0 be the smallest such that vmâˆ‰âŸ¨v0,â€¦,vâ„“âŸ©_mâˆ‰_0,â€¦,v_â„“âŸ©, then obviously mâ‰¥â„“+1â‰¥â„“+1. Since v0,â€¦,vâ„“+1_0,â€¦,v_â„“+1 are linearly dependent, vâ„“+1_â„“+1 is a linear combination of v0,â€¦,vâ„“_0,â€¦,v_â„“. Applying the map Ymâˆ’â„“âˆ’1^m-â„“-1 it follows that vm_m is a linear combination of vmâˆ’â„“âˆ’1,â€¦,vmâˆ’1_m-â„“-1,â€¦,v_m-1. Since by the minimality of m each of these vectors is a linear combination of v0,â€¦,vâ„“_0,â€¦,v_â„“, so is vm_m, and we get the desired contradiction. We'll prove by induction that for every nâˆˆN0âˆˆâ„•_0 and Xâˆˆhâˆˆğ”¥ there exist elements a0,n,X,â€¦,an,n,X_0,n,X,â€¦,a_n,n,X of the base field such that an,n,X=Î»(X)_n,n,X=Î»(X) and Xâ‹…vn=âˆ‘i=0nai,n,Xvi._n=âˆ‘_i=0^na_i,n,Xv_i. The n=0=0 case is straightforward since Xâ‹…v0=Î»(X)v0_0=Î»(X)v_0. Now assume that we have proved the claim for some nâˆˆN0âˆˆâ„•_0 and all elements of hğ”¥ and let Xâˆˆhâˆˆğ”¥. Since hğ”¥ is an ideal, it's [X,Y]âˆˆh[X,Y]âˆˆğ”¥, and thus Xâ‹…vn+1=Yâ‹…(Xâ‹…vn)+[X,Y]â‹…vn=Yâ‹…âˆ‘i=0nai,n,Xvi+âˆ‘i=0nai,n,[X,Y]vi=a0,n,[X,Y]v0+âˆ‘i=1n(aiâˆ’1,n,X+ai,n,[X,Y])vi+Î»(X)vn+1,_n+1=YÂ·(X_n)+[X,Y]_n=YÂ·âˆ‘_i=0^na_i,n,Xv_i+âˆ‘_i=0^na_i,n,[X,Y]v_i=a_0,n,[X,Y]v_0+âˆ‘_i=1^n(a_i-1,n,X+a_i,n,[X,Y])v_i+Î»(X)v_n+1, and the induction step follows. This implies that for every Xâˆˆhâˆˆğ”¥ the subspace U is an invariant subspace of X and the matrix of the restricted map Ï€(X)|UÏ€(X)|_U in the basis Î±Î± is upper triangular with diagonal elements equal to Î»(X)Î»(X), hence trâ¡(Ï€(X)|U)=dimâ¡(U)Î»(X)tr(Ï€(X)|_U)=(U)Î»(X). Applying this with [X,Y]âˆˆh[X,Y]âˆˆğ”¥ instead of X gives trâ¡(Ï€([X,Y])|U)=dimâ¡(U)Î»([X,Y])tr(Ï€([X,Y])|_U)=(U)Î»([X,Y]). On the other hand, U is also obviously an invariant subspace of Y, and so trâ¡(Ï€([X,Y])|U)=trâ¡([Ï€(X),Ï€(Y)]|U])=trâ¡([Ï€(X)|U,Ï€(Y)|U])=0tr(Ï€([X,Y])|_U)=tr([Ï€(X),Ï€(Y)]|_U])=tr([Ï€(X)|_U,Ï€(Y)|_U])=0 since commutators have zero trace, and thus dimâ¡(U)Î»([X,Y])=0(U)Î»([X,Y])=0. Since dimâ¡(U)>0(U)>0 is invertible (because of the assumption on the characteristic of the base field), Î»([X,Y])=0Î»([X,Y])=0 and Xâ‹…(Yâ‹…v)=Yâ‹…(Xâ‹…v)+[X,Y]â‹…v=Yâ‹…(Î»(X)v)+Î»([X,Y])v=Î»(X)(Yâ‹…v),Â·(Y)=YÂ·(X)+[X,Y]=YÂ·(Î»(X)v)+Î»([X,Y])v=Î»(X)(Y), and so Yâ‹…vâˆˆVÎ»_Î». Step 5: Finish up the proof by finding a common eigenvector. Write g=h+Lğ”¤=ğ”¥+L where L is a one-dimensional vector subspace. Since the base field is algebraically closed, there exists an eigenvector in VÎ»_Î» for some (thus every) nonzero element of L. Since that vector is also eigenvector for each element of hğ”¥, the proof is complete. â—»â–¡