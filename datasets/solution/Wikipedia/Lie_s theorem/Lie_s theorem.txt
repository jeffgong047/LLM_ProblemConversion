In mathematics, specifically the theory of Lie algebras, Lie's theorem states that,[1] over an algebraically closed field of characteristic zero, if Ï€:gâ†’gl(V)Ï€:ğ”¤â†’ğ”¤ğ”©(V) is a finite-dimensional representation of a solvable Lie algebra, then there's a flag V=V0âŠƒV1âŠƒâ‹¯âŠƒVn=0=V_0_1âŠƒâ‹¯_n=0 of invariant subspaces of Ï€(g)Ï€(ğ”¤) with codimâ¡Vi=icodimV_i=i,  meaning that Ï€(X)(Vi)âŠ†ViÏ€(X)(V_i)_i for each Xâˆˆgâˆˆğ”¤ and i.
Put in another way, the theorem says there is a basis for V such that all linear transformations in Ï€(g)Ï€(ğ”¤) are represented by upper triangular matrices.[2] This is a generalization of the result of Frobenius that commuting matrices are simultaneously upper triangularizable, as commuting matrices generate an abelian Lie algebra, which is a fortiori solvable.
A consequence of Lie's theorem  is that any finite dimensional solvable Lie algebra over a field of characteristic 0 has a nilpotent derived algebra (see #Consequences). Also, to each flag in a finite-dimensional vector space V, there correspond a Borel subalgebra (that consist of linear transformations stabilizing the flag); thus, the theorem says that Ï€(g)Ï€(ğ”¤) is contained in some Borel subalgebra of gl(V)ğ”¤ğ”©(V).[1]


Counter-example[edit]
For algebraically closed fields of characteristic p>0 Lie's theorem holds provided the dimension of the representation is less than p (see the proof below), but can fail for representations of dimension p. An example is given by the 3-dimensional nilpotent Lie algebra spanned by 1, x, and d/dx acting on the p-dimensional vector space k[x]/(xp), which has no eigenvectors. Taking the semidirect product of this 3-dimensional Lie algebra by the p-dimensional representation (considered as an abelian Lie algebra) gives a solvable Lie algebra whose derived algebra is not nilpotent.

Proof[edit]
The proof is by induction on the dimension of gğ”¤ and consists of several steps. (Note: the structure of the proof is very similar to that for Engel's theorem.) The basic case is trivial and we assume the dimension of gğ”¤ is positive. We also assume V is not zero. For simplicity, we write Xâ‹…v=Ï€(X)(v)=Ï€(X)(v).
Step 1: Observe that the theorem is equivalent to the statement:[3]

There exists a vector in V that is an eigenvector for each linear transformation in Ï€(g)Ï€(ğ”¤).
Indeed, the theorem says in particular that a nonzero vector spanning Vnâˆ’1_n-1 is a common eigenvector for all the linear transformations in Ï€(g)Ï€(ğ”¤). Conversely, if v is a common eigenvector, take Vnâˆ’1_n-1 to its span and then Ï€(g)Ï€(ğ”¤) admits a common eigenvector in the quotient V/Vnâˆ’1/V_n-1; repeat the argument.
Step 2: Find an ideal hğ”¥ of codimension one in gğ”¤.
Let Dg=[g,g]ğ”¤=[ğ”¤,ğ”¤] be the derived algebra. Since gğ”¤ is solvable and has positive dimension, Dgâ‰ gğ”¤â‰ ğ”¤ and so the quotient g/Dgğ”¤/Dğ”¤ is a nonzero abelian Lie algebra, which certainly contains an ideal of codimension one and by the ideal correspondence, it corresponds to an ideal of codimension one in gğ”¤.
Step 3: There exists some linear functional Î»Î» in hâˆ—ğ”¥^* such that

VÎ»=vâˆˆV|Xâ‹…v=Î»(X)v,Xâˆˆh_Î»={v|X=Î»(X)v,Xâˆˆğ”¥}
is nonzero. This follows from the inductive hypothesis (it is easy to check that the eigenvalues determine a linear functional).
Step 4: VÎ»_Î» is a gğ”¤-invariant subspace. (Note this step proves a general fact and does not involve solvability.)
Let Yâˆˆgâˆˆğ”¤, vâˆˆVÎ»_Î», then we need to prove Yâ‹…vâˆˆVÎ»_Î». If v=0=0 then it's obvious, so assume vâ‰ 0â‰ 0 and set recursively v0=v,vi+1=Yâ‹…vi_0=v, v_i+1=Y_i. Let U=spanâ¡vi|iâ‰¥0=span{v_i|iâ‰¥0} and â„“âˆˆN0â„“âˆˆâ„•_0 be the largest such that v0,â€¦,vâ„“_0,â€¦,v_â„“ are linearly independent. Then we'll prove that they generate U and thus Î±=(v0,â€¦,vâ„“)Î±=(v_0,â€¦,v_â„“) is a basis of U. Indeed, assume by contradiction that it's not the case and let mâˆˆN0âˆˆâ„•_0 be the smallest such that vmâˆ‰âŸ¨v0,â€¦,vâ„“âŸ©_mâˆ‰_0,â€¦,v_â„“âŸ©, then obviously mâ‰¥â„“+1â‰¥â„“+1. Since v0,â€¦,vâ„“+1_0,â€¦,v_â„“+1 are linearly dependent, vâ„“+1_â„“+1 is a linear combination of v0,â€¦,vâ„“_0,â€¦,v_â„“. Applying the map Ymâˆ’â„“âˆ’1^m-â„“-1 it follows that vm_m is a linear combination of vmâˆ’â„“âˆ’1,â€¦,vmâˆ’1_m-â„“-1,â€¦,v_m-1. Since by the minimality of m each of these vectors is a linear combination of v0,â€¦,vâ„“_0,â€¦,v_â„“, so is vm_m, and we get the desired contradiction. We'll prove by induction that for every nâˆˆN0âˆˆâ„•_0 and Xâˆˆhâˆˆğ”¥ there exist elements a0,n,X,â€¦,an,n,X_0,n,X,â€¦,a_n,n,X of the base field such that an,n,X=Î»(X)_n,n,X=Î»(X) and

Xâ‹…vn=âˆ‘i=0nai,n,Xvi._n=âˆ‘_i=0^na_i,n,Xv_i.
The n=0=0 case is straightforward since Xâ‹…v0=Î»(X)v0_0=Î»(X)v_0. Now assume that we have proved the claim for some nâˆˆN0âˆˆâ„•_0 and all elements of hğ”¥ and let Xâˆˆhâˆˆğ”¥. Since hğ”¥ is an ideal, it's [X,Y]âˆˆh[X,Y]âˆˆğ”¥, and thus

Xâ‹…vn+1=Yâ‹…(Xâ‹…vn)+[X,Y]â‹…vn=Yâ‹…âˆ‘i=0nai,n,Xvi+âˆ‘i=0nai,n,[X,Y]vi=a0,n,[X,Y]v0+âˆ‘i=1n(aiâˆ’1,n,X+ai,n,[X,Y])vi+Î»(X)vn+1,_n+1=YÂ·(X_n)+[X,Y]_n=YÂ·âˆ‘_i=0^na_i,n,Xv_i+âˆ‘_i=0^na_i,n,[X,Y]v_i=a_0,n,[X,Y]v_0+âˆ‘_i=1^n(a_i-1,n,X+a_i,n,[X,Y])v_i+Î»(X)v_n+1,
and the induction step follows. This implies that for every Xâˆˆhâˆˆğ”¥ the subspace U is an invariant subspace of X and the matrix of the restricted map Ï€(X)|UÏ€(X)|_U in the basis Î±Î± is upper triangular with diagonal elements equal to Î»(X)Î»(X), hence trâ¡(Ï€(X)|U)=dimâ¡(U)Î»(X)tr(Ï€(X)|_U)=(U)Î»(X). Applying this with [X,Y]âˆˆh[X,Y]âˆˆğ”¥ instead of X gives trâ¡(Ï€([X,Y])|U)=dimâ¡(U)Î»([X,Y])tr(Ï€([X,Y])|_U)=(U)Î»([X,Y]). On the other hand, U is also obviously an invariant subspace of Y, and so

trâ¡(Ï€([X,Y])|U)=trâ¡([Ï€(X),Ï€(Y)]|U])=trâ¡([Ï€(X)|U,Ï€(Y)|U])=0tr(Ï€([X,Y])|_U)=tr([Ï€(X),Ï€(Y)]|_U])=tr([Ï€(X)|_U,Ï€(Y)|_U])=0
since commutators have zero trace, and thus dimâ¡(U)Î»([X,Y])=0(U)Î»([X,Y])=0. Since dimâ¡(U)>0(U)>0 is invertible (because of the assumption on the characteristic of the base field), Î»([X,Y])=0Î»([X,Y])=0 and

Xâ‹…(Yâ‹…v)=Yâ‹…(Xâ‹…v)+[X,Y]â‹…v=Yâ‹…(Î»(X)v)+Î»([X,Y])v=Î»(X)(Yâ‹…v),Â·(Y)=YÂ·(X)+[X,Y]=YÂ·(Î»(X)v)+Î»([X,Y])v=Î»(X)(Y),
and so Yâ‹…vâˆˆVÎ»_Î».
Step 5: Finish up the proof by finding a common eigenvector.
Write g=h+Lğ”¤=ğ”¥+L where L is a one-dimensional vector subspace. Since the base field is algebraically closed, there exists an eigenvector in VÎ»_Î» for some (thus every) nonzero element of L. Since that vector is also eigenvector for each element of hğ”¥, the proof is complete. â—»â–¡

Consequences[edit]
The theorem applies in particular to the adjoint representation ad:gâ†’gl(g)ad:ğ”¤â†’ğ”¤ğ”©(ğ”¤) of a (finite-dimensional) solvable Lie algebra gğ”¤ over an algebraically closed field of characteristic zero; thus, one can choose a basis on gğ”¤ with respect to which adâ¡(g)ad(ğ”¤) consists of upper triangular matrices. It follows easily that for each x,yâˆˆg,yâˆˆğ”¤, adâ¡([x,y])=[adâ¡(x),adâ¡(y)]ad([x,y])=[ad(x),ad(y)] has diagonal consisting of zeros; i.e., adâ¡([x,y])ad([x,y]) is a strictly upper triangular matrix. This implies that [g,g][ğ”¤,ğ”¤] is a nilpotent Lie algebra. Moreover, if the base field is not algebraically closed then solvability and nilpotency of a Lie algebra is unaffected by extending the base field to its algebraic closure. Hence, one concludes the statement (the other implication is obvious):[4]

A finite-dimensional Lie algebra gğ”¤ over a field of characteristic zero is solvable if and only if the derived algebra Dg=[g,g]ğ”¤=[ğ”¤,ğ”¤] is nilpotent.
Lie's theorem also establishes one direction in Cartan's criterion for solvability:

If V is a finite-dimensional vector space over a field of characteristic zero and gâŠ†gl(V)ğ”¤âŠ†ğ”¤ğ”©(V) a Lie subalgebra, then gğ”¤ is solvable if and only if trâ¡(XY)=0tr(XY)=0 for every Xâˆˆgâˆˆğ”¤ and Yâˆˆ[g,g]âˆˆ[ğ”¤,ğ”¤].[5]
Indeed, as above, after extending the base field, the implication â‡’â‡’ is seen easily. (The converse is more difficult to prove.)
Lie's theorem (for various V) is equivalent to the statement:[6]

For a solvable Lie algebra gğ”¤ over an algebraically closed field of characteristic zero, each finite-dimensional simple gğ”¤-module (i.e., irreducible as a representation) has dimension one.
Indeed, Lie's theorem clearly implies this statement. Conversely, assume the statement is true. Given a finite-dimensional gğ”¤-module V, let V1_1 be a maximal gğ”¤-submodule (which exists by finiteness of the dimension). Then, by maximality, V/V1/V_1 is simple; thus, is one-dimensional. The induction now finishes the proof.
The statement says in particular that a finite-dimensional simple module over an abelian Lie algebra is one-dimensional; this fact remains true over any base field since in this case every vector subspace is a Lie subalgebra.[7]
Here is another quite useful application:[8]

Let gğ”¤ be a finite-dimensional Lie algebra over an algebraically closed field of characteristic zero with radical radâ¡(g)rad(ğ”¤). Then each finite-dimensional simple representation Ï€:gâ†’gl(V)Ï€:ğ”¤â†’ğ”¤ğ”©(V) is the tensor product of a simple representation of g/radâ¡(g)ğ”¤/rad(ğ”¤) with a one-dimensional representation of gğ”¤ (i.e., a linear functional vanishing on Lie brackets).
By Lie's theorem, we can find a linear functional Î»Î» of radâ¡(g)rad(ğ”¤) so that there is the weight space VÎ»_Î» of radâ¡(g)rad(ğ”¤). By Step 4 of the proof of Lie's theorem, VÎ»_Î» is also a gğ”¤-module; so V=VÎ»=V_Î». In particular, for each Xâˆˆradâ¡(g)âˆˆrad(ğ”¤), trâ¡(Ï€(X))=dimâ¡(V)Î»(X)tr(Ï€(X))=(V)Î»(X). Extend Î»Î» to a linear functional on gğ”¤ that vanishes on [g,g][ğ”¤,ğ”¤]; Î»Î» is then a one-dimensional representation of gğ”¤. Now, (Ï€,V)â‰ƒ(Ï€,V)âŠ—(âˆ’Î»)âŠ—Î»(Ï€,V)â‰ƒ(Ï€,V)âŠ—(-Î»)âŠ—Î». Since Ï€Ï€ coincides with Î»Î» on radâ¡(g)rad(ğ”¤), we have that VâŠ—(âˆ’Î»)âŠ—(-Î») is trivial on radâ¡(g)rad(ğ”¤) and thus is the restriction of a (simple) representation of g/radâ¡(g)ğ”¤/rad(ğ”¤). â—»â–¡

See also[edit]
Engel's theorem, which concerns a nilpotent Lie algebra.
Lieâ€“Kolchin theorem, which is about a (connected) solvable linear algebraic group.
References[edit]


^ a b Serre, Theorem 3 harvnb error: no target: CITEREFSerre (help)

^ Humphreys, Ch. II, Â§ 4.1., Corollary A. harvnb error: no target: CITEREFHumphreys (help)

^ Serre, Theorem 3â€³ harvnb error: no target: CITEREFSerre (help)

^ Humphreys, Ch. II, Â§ 4.1., Corollary C. harvnb error: no target: CITEREFHumphreys (help)

^ Serre, Theorem 4 harvnb error: no target: CITEREFSerre (help)

^ Serre, Theorem 3' harvnb error: no target: CITEREFSerre (help)

^ Jacobson, Ch. II, Â§ 6, Lemma 5. harvnb error: no target: CITEREFJacobson (help)

^ Fulton & Harris, Proposition 9.17. harvnb error: no target: CITEREFFultonHarris (help)


Sources[edit]
Fulton, William; Harris, Joe (1991). Representation theory. A first course. Graduate Texts in Mathematics, Readings in Mathematics. Vol.Â 129. New York: Springer-Verlag. doi:10.1007/978-1-4612-0979-9. ISBNÂ 978-0-387-97495-8. MRÂ 1153249. OCLCÂ 246650103.
Humphreys, James E. (1972), Introduction to Lie Algebras and Representation Theory, Berlin, New York: Springer-Verlag, ISBNÂ 978-0-387-90053-7.
Jacobson, Nathan, Lie algebras, Republication of the 1962 original. Dover Publications, Inc., New York, 1979.  ISBNÂ 0-486-63832-4
Jean-Pierre Serre: Complex Semisimple Lie Algebras, Springer, Berlin, 2001. ISBNÂ 3-5406-7827-1



