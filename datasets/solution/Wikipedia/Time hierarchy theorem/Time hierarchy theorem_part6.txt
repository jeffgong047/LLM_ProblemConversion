Proof: We include here a proof of a weaker result, namely that DTIME(f(n)) is a strict subset of DTIME(f(2n + 1)3), as it is simpler but illustrates the proof idea. See the bottom of this section for information on how to extend the proof to f(n)logf(n). To prove this, we first define the language of the encodings of machines and their inputs which cause them to halt within f Hf=([M],x)|Macceptsxinf(|x|)steps._f={([M],x){accepts{in(|x|){steps}. Notice here that this is a time-class. It is the set of pairs of machines and inputs to those machines (M,x) so that the machine M accepts within f(|x|) steps. Here, M is a deterministic Turing machine, and x is its input (the initial contents of its tape). [M] denotes an input that encodes the Turing machine M. Let m be the size of the tuple ([M], x). We know that we can decide membership of Hf by way of a deterministic Turing machine R, that simulates M for f(x) steps by first calculating f(|x|) and then writing out a row of 0s of that length, and then using this row of 0s as a "clock" or "counter" to simulate M for at most that many steps. At each step, the simulating machine needs to look through the definition of M to decide what the next action would be. It is safe to say that this takes at most f(m)3 operations (since it is known that a simulation of a machine of time complexity T(n) for can be achieved in time O(T(n)â‹…|M|)(T(n)Â·|M|) on a multitape machine, where |M| is the length of the encoding of M), we have that: HfâˆˆTIME(f(m)3)._fâˆˆğ–³ğ–¨ğ–¬ğ–¤(f(m)^3). The rest of the proof will show that Hfâˆ‰TIME(f(âŒŠm2âŒ‹))_fâˆ‰ğ–³ğ–¨ğ–¬ğ–¤(f(âŒŠm/2âŒ‹)) so that if we substitute 2n + 1 for m, we get the desired result. Let us assume that Hf is in this time complexity class, and we will reach a contradiction. If Hf is in this time complexity class, then there exists a machine K which, given some machine description [M] and input x, decides whether the tuple ([M], x) is in Hf within TIME(f(âŒŠm2âŒ‹)).ğ–³ğ–¨ğ–¬ğ–¤(f(âŒŠm/2âŒ‹)). We use this K to construct another machine, N, which takes a machine description [M] and runs K on the tuple ([M], [M]), ie. M is simulated on its own code by K, and then N accepts if K rejects, and rejects if K accepts. If n is the length of the input to N, then m (the length of the input to K) is twice n plus some delimiter symbol, so m = 2n + 1. N{'}}s running time is thus TIME(f(âŒŠm2âŒ‹))=TIME(f(âŒŠ2n+12âŒ‹))=TIME(f(n)).ğ–³ğ–¨ğ–¬ğ–¤(f(âŒŠm/2âŒ‹))=ğ–³ğ–¨ğ–¬ğ–¤(f(âŒŠ2n+1/2âŒ‹))=ğ–³ğ–¨ğ–¬ğ–¤(f(n)). Now if we feed [N] as input into N itself (which makes n the length of [N]) and ask the question whether N accepts its own description as input, we get: If N accepts [N] (which we know it does in at most f(n) operations since K halts on ([N], [N]) in f(n) steps), this means that K rejects ([N], [N]), so ([N], [N]) is not in Hf, and so by the definition of Hf, this implies that N does not accept [N] in f(n) steps. Contradiction. If N rejects [N] (which we know it does in at most f(n) operations), this means that K accepts ([N], [N]), so ([N], [N]) is in Hf, and thus N does accept [N] in f(n) steps. Contradiction. We thus conclude that the machine K does not exist, and so Hfâˆ‰TIME(f(âŒŠm2âŒ‹))._fâˆ‰ğ–³ğ–¨ğ–¬ğ–¤(f(âŒŠm/2âŒ‹)).