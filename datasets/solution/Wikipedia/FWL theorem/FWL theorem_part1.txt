Theorem in statistics and econometrics In econometrics, the Frisch‚ÄìWaugh‚ÄìLovell (FWL) theorem is named after the econometricians Ragnar Frisch, Frederick V. Waugh, and Michael C. Lovell.[1][2][3] The Frisch‚ÄìWaugh‚ÄìLovell theorem states that if the regression we are concerned with is expressed in terms of two separate sets of predictor variables: Y=X1Œ≤1+X2Œ≤2+u=X_1Œ≤_1+X_2Œ≤_2+u where X1_1 and X2_2 are matrices, Œ≤1Œ≤_1 and Œ≤2Œ≤_2 are vectors (and u is the error term), then the estimate of Œ≤2Œ≤_2 will be the same as the estimate of it from a modified regression of the form: MX1Y=MX1X2Œ≤2+MX1u,_X_1Y=M_X_1X_2Œ≤_2+M_X_1u, where MX1_X_1 projects onto the orthogonal complement of the image of the projection matrix X1(X1TX1)‚àí1X1T_1(X_1^ùñ≥X_1)^-1X_1^ùñ≥. Equivalently, MX1 projects onto the orthogonal complement of the column space of X1. Specifically, MX1=I‚àíX1(X1TX1)‚àí1X1T,_X_1=I-X_1(X_1^ùñ≥X_1)^-1X_1^ùñ≥, and this particular orthogonal projection matrix is known as the residual maker matrix or annihilator matrix.[4][5] The vector MX1Y_X_1Y is the vector of residuals from regression of Y on the columns of X1_1. The most relevant consequence of the theorem is that the parameters in Œ≤2Œ≤_2 do not apply to X2_2 but to MX1X2_X_1X_2, that is: the part of X2_2 uncorrelated with X1_1. This is the basis for understanding the contribution of each single variable to a multivariate regression (see, for instance, Ch. 13 in [6]). The theorem also implies that the secondary regression used for obtaining MX1_X_1 is unnecessary when the predictor variables are uncorrelated: using projection matrices to make the explanatory variables orthogonal to each other will lead to the same results as running the regression with all non-orthogonal explanators included. Moreover, the standard errors from the partial regression equal those from the full regression.[7]