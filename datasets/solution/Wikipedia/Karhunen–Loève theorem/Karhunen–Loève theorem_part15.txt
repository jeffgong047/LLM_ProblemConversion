matrix: Recall that the main implication and difficulty of the KL transformation is computing the eigenvectors of the linear operator associated to the covariance function, which are given by the solutions to the integral equation written above. Define Σ, the covariance matrix of X, as an N × N matrix whose elements are given by: Σij=E[XiXj],∀i,j∈1,…,NΣ_ij=𝐄[X_iX_j], ,j∈{1,…,N} Rewriting the above integral equation to suit the discrete case, we observe that it turns into: ∑j=1NΣijej=λei⇔Σe=λe∑_j=1^NΣ_ije_j=_i ⇔ = where e=(e1e2…eN)T=(e_1 e_2 … e_N)^T is an N-dimensional vector. The integral equation thus reduces to a simple matrix eigenvalue problem, which explains why the PCA has such a broad domain of applications. Since Σ is a positive definite symmetric matrix, it possesses a set of orthonormal eigenvectors forming a basis of RNℝ^N, and we write λi,φii∈1,…,N{λ_i,φ_i}_i∈{1,…,N} this set of eigenvalues and corresponding eigenvectors, listed in decreasing values of λi. Let also Φ be the orthonormal matrix consisting of these eigenvectors: Φ:=(φ1φ2…φN)TΦTΦ=IΦ :=(φ_1 φ_2 … φ_N)^T Φ^TΦ =I Principal component