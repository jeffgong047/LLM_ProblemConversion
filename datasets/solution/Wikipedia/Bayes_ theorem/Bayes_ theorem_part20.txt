form: For events A and B, provided that P(B) ≠ 0, P(A|B)=P(B|A)P(A)P(B).(A|B)=P(B|A)P(A)/P(B). In many applications, for instance in Bayesian inference, the event B is fixed in the discussion, and we wish to consider the impact of its having been observed on our belief in various possible events A. In such a situation the denominator of the last expression, the probability of the given evidence B, is fixed; what we want to vary is A. Bayes' theorem then shows that the posterior probabilities are proportional to the numerator, so the last equation becomes: P(A|B)∝P(A)⋅P(B|A).(A|B)(A)(B|A). In words, the posterior is proportional to the prior times the likelihood.[21] If events A1, A2, ..., are mutually exclusive and exhaustive, i.e., one of them is certain to occur but no two can occur together, we can determine the proportionality constant by using the fact that their probabilities must add up to one. For instance, for a given event A, the event A itself and its complement ¬A are exclusive and exhaustive. Denoting the constant of proportionality by c we have P(A|B)=c⋅P(A)⋅P(B|A)andP(¬A|B)=c⋅P(¬A)⋅P(B|¬A).(A|B)=c(A)(B|A)andP(|B)=c()(B|). Adding these two formulas we deduce that 1=c⋅(P(B|A)⋅P(A)+P(B|¬A)⋅P(¬A)),1=c·(P(B|A)(A)+P(B|)()), or c=1P(B|A)⋅P(A)+P(B|¬A)⋅P(¬A)=1P(B).=1/P(B|A)(A)+P(B|)()=1/P(B). Alternative