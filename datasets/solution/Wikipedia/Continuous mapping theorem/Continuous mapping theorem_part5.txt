probability: Fix an arbitrary ε > 0. Then for any δ > 0 consider the set Bδ defined as Bδ=x∈S∣x∉Dg:∃y∈S:|x−y|<δ,|g(x)−g(y)|>ε._δ={x_g: existsy:x-y|<δ, |g(x)-g(y)|>ε}. This is the set of continuity points x of the function g(·) for which it is possible to find, within the δ-neighborhood of x, a point which maps outside the ε-neighborhood of g(x). By definition of continuity, this set shrinks as δ goes to zero, so that limδ → 0Bδ = ∅. Now suppose that |g(X) − g(Xn)| > ε. This implies that at least one of the following is true: either |X−Xn| ≥ δ, or X ∈ Dg, or X∈Bδ. In terms of probabilities this can be written as Pr(|g(Xn)−g(X)|>ε)≤Pr(|Xn−X|≥δ)+Pr(X∈Bδ)+Pr(X∈Dg).(|g(X_n)-g(X)|>ε)≤(|X_n-X|≥δ)+(X_δ)+(X_g). On the right-hand side, the first term converges to zero as n → ∞ for any fixed δ, by the definition of convergence in probability of the sequence {Xn}. The second term converges to zero as δ → 0, since the set Bδ shrinks to an empty set. And the last term is identically equal to zero by assumption of the theorem. Therefore, the conclusion is that limn→∞Pr(|g(Xn)−g(X)|>ε)=0,lim_n→∞(|g(X_n)-g(X)|>ε)=0, which means that g(Xn) converges to g(X) in probability. Almost sure