channels: Suppose a code of 2nR2^nR codewords. Let W be drawn uniformly over this set as an index. Let Xn^n and Yn^n be the transmitted codewords and received codewords, respectively. nR=H(W)=H(W|Yn)+I(W;Yn)=H(W)=H(W|Y^n)+I(W;Y^n) using identities involving entropy and mutual information ≤H(W|Yn)+I(Xn(W);Yn)(W|Y^n)+I(X^n(W);Y^n) since X is a function of W ≤1+Pe(n)nR+I(Xn(W);Yn)≤1+P_e^(n)nR+I(X^n(W);Y^n) by the use of Fano's Inequality ≤1+Pe(n)nR+nC≤1+P_e^(n)nR+nC by the fact that capacity is maximized mutual information. The result of these steps is that Pe(n)≥1−1nR−CR_e^(n)≥1-1/nR-C/R. As the block length n goes to infinity, we obtain Pe(n)_e^(n) is bounded away from 0 if R is greater than C - we can get arbitrarily low rates of error only if R is less than C. Strong converse for discrete memoryless