statement: The basic mathematical model for a communication system is the following: →MessageWEncoderfn→EncodedsequenceXnChannelp(y|x)→ReceivedsequenceYnDecodergn→EstimatedmessageW^[ Encoder; f_n; ][ Channel; p(y|x); ][ Decoder; g_n; ] A message W is transmitted through a noisy channel by using encoding and decoding functions. An encoder maps W into a pre-defined sequence of channel symbols of length n. In its most basic model, the channel distorts each of these symbols independently of the others. The output of the channel –the received sequence– is fed into a decoder which maps the sequence into an estimate of the message. In this setting, the probability of error is defined as: Pe=PrW^≠W._e=Pr{Ŵ}. Theorem (Shannon, 1948): 1. For every discrete memoryless channel, the channel capacity, defined in terms of the mutual information I(X;Y)(X;Y) as C=suppXI(X;Y)=sup_p_XI(X;Y)[2] has the following property. For any ϵ>0ϵ>0 and R<C<C, for large enough N, there exists a code of length N and rate ≥R and a decoding algorithm, such that the maximal probability of block error is ≤ϵ≤ϵ. 2. If a probability of bit error pb_b is acceptable, rates up to R(pb)(p_b) are achievable, where R(pb)=C1−H2(pb).(p_b)=C/1-H_2(p_b). and H2(pb)_2(p_b) is the binary entropy function H2(pb)=−[pblog2⁡pb+(1−pb)log2⁡(1−pb)]_2(p_b)=-[p_blog_2p_b+(1-p_b)log_2(1-p_b)] 3. For any pb_b, rates greater than R(pb)(p_b) are not achievable. (MacKay (2003), p. 162; cf Gallager (1968), ch.5; Cover and Thomas (1991), p. 198; Shannon (1948) thm. 11) Outline of