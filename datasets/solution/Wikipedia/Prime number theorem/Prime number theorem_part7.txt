integral: In a handwritten note on a reprint of his 1838 paper "Sur l'usage des séries infinies dans la théorie des nombres", which he mailed to Gauss, Dirichlet conjectured (under a slightly different form appealing to a series rather than an integral) that an even better approximation to π(x) is given by the offset logarithmic integral function Li(x), defined by Li⁡(x)=∫2xdtlog⁡t=li⁡(x)−li⁡(2).Li(x)=∫_2^xdt/=li(x)-li(2). Indeed, this integral is strongly suggestive of the notion that the "density" of primes around t should be 1 / log t. This function is related to the logarithm by the asymptotic expansion Li⁡(x)∼xlog⁡x∑k=0∞k!(log⁡x)k=xlog⁡x+x(log⁡x)2+2x(log⁡x)3+⋯Li(x)∼x/∑_k=0^∞k!/()^k=x/+x/()^2+2x/()^3+⋯ So, the prime number theorem can also be written as π(x) ~ Li(x). In fact, in another paper[17] in 1899 de la Vallée Poussin proved that π(x)=Li⁡(x)+O(xe−alog⁡x)asx→∞π(x)=Li(x)+O(xe^-a√()) asx→∞ for some positive constant a, where O(...) is the big O notation. This has been improved to π(x)=li⁡(x)+O(xexp⁡(−A(log⁡x)35(log⁡log⁡x)15))π(x)=li(x)+O(xexp(-A()^3/5/(log)^1/5)) where A=0.2098=0.2098.[18] In 2016, Trudgian proved an explicit upper bound for the difference between π(x)π(x) and li⁡(x)li(x): |π(x)−li⁡(x)|≤0.2795x(log⁡x)3/4exp⁡(−log⁡x6.455)|π(x)-li(x)|≤0.2795x/()^3/4exp(-√(/6.455)) for x≥229≥229.[19] The connection between the Riemann zeta function and π(x) is one reason the Riemann hypothesis has considerable importance in number theory: if established, it would yield a far better estimate of the error involved in the prime number theorem than is available today. More specifically, Helge von Koch showed in 1901[20] that if the Riemann hypothesis is true, the error term in the above relation can be improved to π(x)=Li⁡(x)+O(xlog⁡x)π(x)=Li(x)+O(√(x)) (this last estimate is in fact equivalent to the Riemann hypothesis). The constant involved in the big O notation was estimated in 1976 by Lowell Schoenfeld:[21] assuming the Riemann hypothesis, |π(x)−li⁡(x)|<xlog⁡x8π|π(x)-li(x)|<√(x)/8π for all x ≥ 2657. He also derived a similar bound for the Chebyshev prime-counting function ψ: |ψ(x)−x|<x(log⁡x)28π|ψ(x)-x|<√(x)()^2/8π for all x ≥ 73.2 . This latter bound has been shown to express a variance to mean power law (when regarded as a random function over the integers) and 1/ f noise and to also correspond to the Tweedie compound Poisson distribution. (The Tweedie distributions represent a family of scale invariant distributions that serve as foci of convergence for a generalization of the central limit theorem.[22]) The logarithmic integral li(x) is larger than π(x) for "small" values of x. This is because it is (in some sense) counting not primes, but prime powers, where a power pn of a prime p is counted as 1/ n of a prime. This suggests that li(x) should usually be larger than π(x) by roughly 12li⁡(x),{12li(√(x)) and in particular should always be larger than π(x). However, in 1914, J. E. Littlewood proved that π(x)−li⁡(x) pi(x)-li(x)} changes sign infinitely often.[23] The first value of x where π(x) exceeds li(x) is probably around x ~ 10316 ; see the article on Skewes' number for more details. (On the other hand, the offset logarithmic integral Li(x) is smaller than π(x) already for x = 2; indeed, Li(2) = 0, while π(2) = 1.) Elementary